{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import PIL\n",
    "\n",
    "#from utils import *\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y: [1. 0. 1. 4. 0. 0. 7. 3. 5. 3.]\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('./train.csv', delimiter=',')\n",
    "data = np.delete(data, (0), axis=0)\n",
    "data_np_y = data[:,0]\n",
    "data = np.delete(data, (0), axis=1)\n",
    "data_np_x = data / 255\n",
    "\n",
    "\n",
    "pos = int(data_np_x.shape[0] * 0.75)\n",
    "\n",
    "train_np_y = data_np_y[:pos]\n",
    "train_np_x = data_np_x[:pos]\n",
    "test_np_y = data_np_y[pos:]\n",
    "test_np_x = data_np_x[pos:]\n",
    "\n",
    "print (\"Y: {}\".format(train_np_y[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000,)\n",
      "(31500, 784) (31500,)\n",
      "(10500, 784) (10500,)\n"
     ]
    }
   ],
   "source": [
    "print (data_np_x.shape, data_np_y.shape)\n",
    "print (train_np_x.shape, train_np_y.shape)\n",
    "print (test_np_x.shape, test_np_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10500, 784) (10500,)\n"
     ]
    }
   ],
   "source": [
    "print (test_np_x.shape, test_np_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABO4AAACACAYAAAC8ySaKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHodJREFUeJzt3Xl0VPX5x/EbloQdxKAIIaBQWQoYWwQaCYvsEJB9kV0U2SxbqRRRVg+bskgaQDwgSOGwL6JUlrIfCVELSMpSW5pA2BI5AUJKWJzfH57f7X2ekJlMMjO5k3m//no+5ztz5ys3mbnz9X6fBDkcDgMAAAAAAACAvRTK7wkAAAAAAAAAyIqFOwAAAAAAAMCGWLgDAAAAAAAAbIiFOwAAAAAAAMCGWLgDAAAAAAAAbIiFOwAAAAAAAMCGWLgDAAAAAAAAbIiFOwAAAAAAAMCGWLgDAAAAAAAAbIiFOwAAAAAAAMCGirj7hJCQEEeFChW8MRd4SEpKipGZmRnkyWNy3u2P8x6YOO+BifMemDjvgYnzHpg474GJ8x6YOO+ByZ3z7vbCXYUKFYzLly+7Pyv4TFhYmMePyXm3P857YOK8BybOe2DivAcmzntg4rwHJs57YOK8ByZ3zjtbZQEAAAAAAAAbYuEOAAAAAAAAsCEW7gAAAAAAAAAbYuEOAAAAAAAAsCEW7gAAAAAAAAAbYuEOAAAAAAAAsCEW7gAAAAAAAAAbYuEOAAAAAAAAsCEW7gAAAAAAAAAbYuEOAAAAAAAAsCEW7gAAAAAAAAAbYuEOAAAAAAAAsKEi+T2Bgq5ly5Zm/be//U2MrV69WuSBAwf6ZE4Fyc2bN0VOT0836z//+c9OnxsXFyfyyJEjRS5TpoxZt23bVowFBQW5NU/4zqNHj0SeOHGiyIULFxZ5zpw5TscB+JbD4RD52rVrIsfGxpr1lStXxNjKlSvdeq0hQ4aY9bRp08RYWFiYyIUK8f867cLV+/zRo0dFjo+PF7lp06Zmra8V6tat64kpAgAQEB48eCCy/o69a9cup8+/e/euWcfExDh9bOPGjUXu06ePyAMGDDDr4sWLizGd/Q1XoQAAAAAAAIANsXAHAAAAAAAA2BALdwAAAAAAAIAN0ePOw1q0aCHysWPHzFr3RaNPmmt37twReffu3SL3799fZL3H3h1Xr14VOSkpyawHDx4sxt555x2Rq1WrluvXhWfdv39f5IULFzp9/MyZM0Wmx513Va9e3azr1KkjxrZs2SJycHCwT+ak/fe//xV53759Infq1MmX0ynw7t27J7Lu/zp8+HCvvfaqVaseWxuGYXz00Ucijx07VmR63vmW9fN90KBBYmz9+vUiR0dHi6yvFTZu3GjWul/O5s2bRW7Xrp37kwUAeNTZs2dFXrJkiciZmZki37hxw6xd9Vhr2LChyN26dTPr9u3bi7H69eu7nmwAsH5vnj59uhj75JNPcn1cV+sjun+ezuPGjTPrGTNmiLEpU6bkel52wFUnAAAAAAAAYEMs3AEAAAAAAAA2xMIdAAAAAAAAYEP0uMujWbNmifzNN9+I/PDhQ7Pu3bu3GOvevbv3Juan0tLSRB4wYIDIrnoU5MWFCxeyHVu2bJnI27dvF3nHjh0i16xZ06zLli3rgdkBBcOhQ4fM+le/+pUYu3v3rsj51ePu5s2bIus+iPS4yxt9niMjI0U+ffq0L6eTrQkTJoisfx5Hjx7ty+kEvPfff9+sdU+7ESNGiBwbG+v0WMnJyWZ94MABMdazZ0+Rz5w5I3LVqlVdTxaAUykpKSLrfmVHjx41a/07qhUtWlTkjh07ilyrVi2ztl6fP06XLl1ELlWqlFkXKcLXZm+z9jafPHmyGFuzZk22j30ch8Nh1q76psXHx2ebdf+2Xr16ifzZZ585PXZB9fHHH5u17kFfokQJkTMyMkRu0KCByNaeweXLlxdjOn/77bciO/v+vmHDBpGtn/2GYRhLly7N9rl2xB13AAAAAAAAgA2xcAcAAAAAAADYEPf8uklvkfzggw9Evn//vsjWPxmt/zSyvo0UhnH8+HGRvbk1Ni+uXbsmcqNGjUS23no7fPhwn8wJubNy5UqRR44cmU8zCQxhYWFmrbe3/PGPfxR5xYoVPpmTK3oLhXW7r2EYRrNmzXw5Hb+Xmpoqsl22xroSExMjckhIiFm//vrrYqxw4cI+mVNBtnXrVpEXLlxo1tZrK8MwjMWLF7t17EqVKpm13oajt8pv3rxZZL2FGllZz92ePXvEWNeuXUUODQ11eqzw8HCz1u8devuVOw4fPiyyvr6vXbu2yNZte9Y54X+uXLli1vr6Xf8e7d271+mxrO+v1apVc/rYn3/+WWR9Lt0xZMgQkSMiIsx60KBBYky3S2ArrfsSExNFtl5PJSUlOX1uhw4dRNbtLNzZKuvM3//+d5H19kvdEmn+/PlO51VQzJ4926x1u4o5c+aI3K5dO5H1dnZ3rpn058CCBQuyfe2EhAQx5mp7td1xxx0AAAAAAABgQyzcAQAAAAAAADbEwh0AAAAAAABgQ2zGz4FLly6Ztf6T0JmZmSI/+eSTIs+cOdOsS5cu7YXZ+b8jR46Y9dy5c732OtY/W20YsseNYRjGhx9+KLLut+eOiRMnmrX+mejZs2eujwvP27lzp8j0uPOdbt26iaz/xLvuGWqXPiG6nw5cu379ullHR0fn6VjWn4PevXuLMevnyePo/qT37t3L8eueP39e5GHDhpl106ZNxVjNmjVzfFz8Qp+LqVOnimy93rL2kTWMrP0yXVm7dq1ZX7x4UYxFRkaKvGrVKpHffvtts7bLe5LdnDt3zqx1f2fdu9Tah8owsvaictbj7u7du06f6+zYrl7X+t9gGLLHHR7P2rfq5MmTTh/buXNnkZs0aZLtuKv3U3293rx5c5Gt1/8NGzZ0eqy4uDiR169fb9bjxo0TY9bPNcOQPb/wePp7c9++fUW29rzTv5N9+vQR2fo+bhiGUaiQd+5HSk9PF3ndunUi636suvdmIHxO6L6fsbGxXnstfa2we/dur72W3XDHHQAAAAAAAGBDLNwBAAAAAAAANsTCHQAAAAAAAGBD9Lh7jBMnToj85ptvmvUPP/zg9LlLliwRuVOnTp6bWAG1aNEisz548KBbz33ppZdEbtSoUbaP1T0v6tWrJ3K7du1EvnnzplnrvnS6B4Zm7YewceNGMUaPO+AXzz77rMirV68W+datWyJXqFDB63MyDMMICQkRuVy5cj553YJswYIFZn3mzBm3nluxYkWRrT2z3P2M3bNnj8ijRo0y6x9//NGtY1m9+uqrIk+ZMkXk/v375/rYgWLx4sUi65+T119/3aydfda7q2zZsk7HExISRE5OTjZr/R6GX1j7gC5btkyMRUVFieyqL6UnHT161Kw///xzp4/t16+fyLqHE7KaMGGCWf/0009izNr/zjAMo0aNGh573bS0NJE//fRTkd15/42IiBDZ+nNQt25dMfbll1+KPGPGDJHd7b0ZCMaMGSOys37i+rxZvy8ahvd62mmlSpUS2drf9nEZ3vX999+LfOrUqXyaie9xxx0AAAAAAABgQyzcAQAAAAAAADbEwh0AAAAAAABgQ/S4M7L2uRg4cKDIQUFBZq17obRu3Vrktm3benh2BY/D4XCanVm3bp3ITz31lMgtW7bM9bxKliyZbdb97+Lj40W29nPRzp49K/KuXbtEjo6OdmueQEHxm9/8Jr+n8FihoaEi6742cO3Bgwci79y5M9fHql69ush56R3bpk0bka09mWbPni3GkpKScnzc8+fPizxr1iyRmzVrJnKVKlVyfOyCKiMjQ2RXPccmT55s1oULF/bYPHQvzWvXrnns2IFqx44dZm3tE20YhlG7dm2n2Zu2bdtm1tZre8MwjDp16ohs/XlDzuRXL099je4O3S9r/fr1Iq9YscKs9XvF/v37RaannWtbtmwRWX8HHDJkiFkvXLhQjLnqR4qCSV9PpqSkiKyv2VNTU70+p/zCHXcAAAAAAACADbFwBwAAAAAAANgQC3cAAAAAAACADQVkj7vr16+LPH/+/Bw/t0uXLiKvWrXKI3MKJKdPnxbZ2nPElSZNmojsqz5B06ZNE7levXoi9+jRI9vnJiQkiPzFF1+ITI87z9K9j3RPqz179vhyOnAiJCQkv6eQK/p3uEWLFvk0E/tavHixyOfOncvxc/XPxaRJkzwyp8cZPny4WXfu3FmMde3aVeQTJ07k+Li6512rVq1E1p8LRYoE3uVYbGysyPrfRPdGq1atmrenBC9w53ff0+7evStyYmKiWeveWvp9RvdNgv/IzMwUecGCBWb96aefirF///vfIut+19ZevPqzn55rrn311Vci6z6Butekta+du/++aWlpIj98+DDb13nyySfdOja86/bt22atv3Nbe6YahmEUKiTvO3v06FGOX0f/jOjexuPHjzdrO35H4Y47AAAAAAAAwIZYuAMAAAAAAABsKCD2ZujbIvXWuTNnzjh9fpkyZcxab6WB+y5evJjjx+rbpO3yp9YjIyNF1vPUt4LDd4KDg0UePHiwyGyVtQ/re6th+M92wU2bNols3YaDX0ycODHXz23QoIHIvmonUKlSJZF1G4e8bJ29cOGCyHqbXiC6d++e0/GaNWuKrNsgeMr06dOdjpcrV07kEiVKeGUe/uzs2bMiW7fH6i3PvqS36Vq3sHfr1k2M6Yy80b/feouqdRujK88884zIV69eFTkpKUnkXbt2ZTvetm1bMbZ8+XKRIyIiRGbLtHv0NuWZM2eK7Oq8O9seq8/70qVLnebU1FSzLlasmBgbNmyYyLptlv4uAe/KyMgw60WLFuXpWNZt0HpbbUpKisjvvvuuyAcPHjTrWbNmibGXXnopT/PyBO64AwAAAAAAAGyIhTsAAAAAAADAhli4AwAAAAAAAGzIPxoK5ZH+c/A//PCDW8+/dOmSWZcuXdojcwpkul+MMw0bNhT5iSee8PR0ckX32+jQoYPI69evz/a5X3/9tcjp6ekilypVKo+zC2y6f8Y333yTTzOBK40bNxY5LCxM5ClTpogcExMjsq96Xnbs2FHkOXPmiHznzh2z5jMi74YMGZLfUzAMI2vPu+3bt4v84osvmvX169fdOnZiYqLINWrUcHN2/m/Hjh1Ox7t06eKTeej+g1pUVJTITz/9tDenUyDYpS9Y//79Rbb2ltS9zuhd6Fl79+4VWfeCdafftSvh4eEi/+lPfxK5RYsWZq17Z8KzrNdDhmEYcXFxTh/fqVMnka29EOfOnSvGdH+y27dv53heuvfekiVLRNbvWe+9916Oj428s64NDB8+XIy5+lsE2kcffWTW+ppcfyccOnSoyNb3Ld1vcePGjW7Nwxu44w4AAAAAAACwIRbuAAAAAAAAABti4Q4AAAAAAACwoQLb4y41NdWso6OjxZi1x8Xj6L5LwcHBnptYANI9CPr06ZPj5+oeGTdu3BC5SpUquZ+YB7322msiO+txp3sbPXjwwCtzClT631P3sYB9WXubGIZhtGvXTuRx48aJXKtWLa/PyTCy9jq7deuWyMePHzfr1q1b+2RO8D3d27RYsWK5PtaaNWtEnjFjRq6P5S90H8Aff/xR5GeffVbkihUren1OhuH6mlD32kVWtWvXFjk+Pj6fZiKdP39e5KCgoHyaSeDRvctatmwpsr6ed8fKlStF3rRpk8h/+ctfRP7d736X69eCe3RfMN0j9MiRIyJ/8cUXIu/cudOsXf2+6vfmevXqZfvYzZs3i6yv45YuXSrysGHDzJq+pt5nvZ6KjY312uts3brVa8f2Be64AwAAAAAAAGyIhTsAAAAAAADAhli4AwAAAAAAAGyowPa4Gz16tFmfOnVKjOk985GRkSLv379f5JCQEA/PLrA8fPhQZN3npiAICwvL7ykAfk/3wHniiSdEHjt2rMh//etfvT4nwzCMjh07ily8eHGfvC7sbfDgwWY9ffr0/JtIAVG3bl2RS5Ys6bXXysjIMGtrT+TH4fPdfaGhofnyuocPHxbZWf9C3XsL3lWiRAmRq1Wrlutj6Z6gU6ZMEVn3K7P2y9X97jZs2CBy0aJFcz0vZP33mzVrlsitWrUS+f79+yKXKVPGrPv16yfGJk2aJHJ4eHiO53X06FGR09LSRL569arI//rXv8yaHnf+Ky4uTuQPP/wwn2biGdxxBwAAAAAAANgQC3cAAAAAAACADbFwBwAAAAAAANhQgelxp3uUWPema8HBwSLrPfP0tPOscuXKidy/f3+R165d68vpAPBTZcuWzZfX1e9hL7zwgsgLFy4065dfflmM6b4+KDju3LmT6+fWqlXLgzPxD5mZmSJb+8wZhmEkJyf7bC63bt0ya93rSHvuuee8PR14yLlz50TWPa27d+9u1rVr1/bJnAoy3UO8SpUqZl2+fHmfzUN/rxszZozIbdu2NWvdY61Ro0Yib9q0SeTq1at7YooBS/eSTEhIEPnRo0ciW3sIu9PDzl36vUH35axcubLXXhu+8+WXX4rs6vPe7rjjDgAAAAAAALAhFu4AAAAAAAAAG/LbrbI3btwQuW/fviJ/9913Zl2sWDExtnz5cpGjo6M9PDtYFSok14dbt24tsjtbZXv27Cnyvn37RC5VqpSbs8sdfavtoEGDcvzcESNGiKy34QH4RZcuXUT+9ttvRX748KFZFyni/OPsypUrIp8+fVrk48ePm7W+tf7Bgwci6+1BVrNnzxZ55syZTucF/7Fz506RY2Jicn0s/VkWCPTvqN7e5kv79+83a91qRbdLqVSpkk/mhLw7cuSIyA6HQ+RXX33Vl9MpcPR3L309f/DgQbP25VZZV6ytCTZv3izG3njjDZFbtGghsvV7xvPPP++F2QWWGjVq+Oy1zp49a9b6GlD77W9/K3LVqlW9MifknfXa3zAM4969eyJbr80OHTrk1rFr1qxp1gsWLMjF7LyLO+4AAAAAAAAAG2LhDgAAAAAAALAhFu4AAAAAAAAAG/LbHnfbtm0T+cCBA9k+Vv+p7wEDBnhlTsgZ3WMkIiLCrE+ePOn0uXFxcSK/8sorIs+ZMyfbsbxISUkR+Q9/+IPIul+WlfVPmxuGYbzzzjsi6z9JDuAX+r16xYoVIlv7x+lekbt37xb56NGjIuu+dVFRUWY9depUMRYaGiry9u3bRZ47d65ZR0ZGGsibefPmiax7Dj333HM+mcfFixdF1r0P79+/n+NjLVmyRGRXPRkLoszMTJHT09N99trWnnaGYRijRo3K9rHjx48X2Zc9mZA3586dE1lfX9WpU8eX0ylwvvrqK5F1j3B/+Pdt3LixyPq/qW3btiJb+1Lv2rVLjOnre9jL4MGDzfrOnTtOH9u1a1cvzwa5pa8dfv/734usvxu4Q79nWd8PwsLCcn1cb+GOOwAAAAAAAMCGWLgDAAAAAAAAbIiFOwAAAAAAAMCG/KbJyvr160XWfcK0l19+2azXrVvnlTkhd8qWLSuytffP8OHDxVhCQoLTY8XHx4s8bdo0sy5fvrzT55YpU0ZkvYfemgcNGiTGnPW00zp27Chy1apVc/xcuG/06NH5PQV4SP369UWuWbOmyMuWLcv2uR06dBB5wYIFIjdo0MBpdka/t1h73OEX1t6lhuG6f6nVhQsXRI6JiRFZn8u8SEpKMuvFixeLsTVr1oicmpqa4+O+8cYbIo8cOVJkeptmlZGRIbL+TA4JCcnxsb7//nuRdf8ia78ja39Lw8jaPwf29d133znNDofDl9MJOLq3rD8KDw8Xefr06SL37t3brI8dOybGWrVq5b2JwW362uDEiRNmrT9z9Wf0kCFDvDexAsraB3j58uViTPeZb968ucjBwcEiJycnm7XuVaqvsfft2+f2XP+f7lmtexfr9wO74Y47AAAAAAAAwIZYuAMAAAAAAABsiIU7AAAAAAAAwIZs2+Pu1q1bIk+ZMkXk27dvO33+hAkTzPqZZ57x3MTgcU2aNDHr999/X4wNHTpU5PT0dKfHOnLkiFm/+OKLTh/71FNPiaz767h6rZzq2bOnR46DnLl8+XJ+TwEeovth6r4X+UX3yEBWBw4cELlFixZm7U6/O8OQfVANwzD2799v1m+99ZZbx1q9erXI1n56aWlpbh3Lql69eiJ/8MEHIhcqxP8nDQsLE7lp06YiHz58WOSvv/5a5M6dO2d77J9++knknTt3imztaWcY8rpj5cqVYqxixYrZvg7sjd6R3qW/T8XGxops/e6mP7/9RZcuXUSuVauWWW/ZskWM0eMuf+nPDOt3f6106dIi63WFokWLem5iBdSVK1dEjoyMNOvr16+LsXnz5oncrFkzkYsVKyay9fo+MTExT/O09rTVvfJ1L31/6zvPlSQAAAAAAABgQyzcAQAAAAAAADZk262yO3bsENn6J4dzwtVWWthTr169RNbbHp3dBu2uGzdueOxY5cqVE9n6Z7E7duzosdcBAH+g3xPfe+89s+7evbtbx3r48KHIp0+fNutRo0blYnaeYd0eu2/fPjGmWzEg61ak1157TWS97WnMmDEiFynyv0vWvXv3irG1a9eKnJqaKnLlypVFHjt2rFnXqFHD2bThRxwOh9OMvImKihL50qVLIlu3t/fo0UOM+Uu7gODgYJGtW+ePHz/u6+kENN3CKCYmRuT58+eLrLfKWz9z9NbN8PBwT0wxoOjzYb3O01tltUOHDnllTo9jbbulr8X8vX2af7yLAgAAAAAAAAGGhTsAAAAAAADAhli4AwAAAAAAAGzItj3udC+UwoULi/zo0SORrb1PDMMw/vnPf3pnYvCpN998U2TdR2j37t2+nI6pVKlSIm/YsEHkNm3a+HI6AHyodOnSIkdERJi1u/1YA0XXrl3N+vPPPxdjAwYM8PV0cqRWrVoiW/v0GYbs1RcSEuKTORUk7du3F1n/Xv3nP/8R2Z1+sbqf1qJFi0R2t88i/IPucaV/h3WGe0qUKCGy7hs2cOBAs05ISBBjkydPFtmu75m6b9rJkyfNeurUqb6ejt+Li4sT+cqVKyJbrw0MwzA++eQTs16yZIkY0z9TrowfP96s33rrLbeei6yqVq0q8rRp08x60qRJYiwxMdGtY1vfW/r37y/GrL0zH8d6ng3DMH7961+btV4f8nfccQcAAAAAAADYEAt3AAAAAAAAgA2xcAcAAAAAAADYkG03/vbt21fkGTNmiKx73L377rsiDxo0yDsTg0/pnjdbt24VWfe827Nnj1nr3gjuevvtt81a97XQe+bLli2bp9eC5+g+KtafiZw8HnBF92CtUKGCWcfHx/t6On7B2nuqX79+YqxDhw4i635kO3bsEPn06dO5noe+NggPDzdr3f+qV69eIhe0Xin5zfpvbxhZexOfPXtW5DVr1pj1P/7xDzFWqVIlkceNGydyVFRUrucJ+1qxYoXIDodD5FmzZomse7Qhb3R/Uuu//7Bhw8TY9u3bRZ4zZ47I+ndU95L2FP3esXTpUpFjY2NFnjhxolnTJ819165dE9naB9EwDKN48eIip6SkmLXuWak9//zzIg8dOlRk67lD3ulr39DQULPesmWLGNPrNmFhYSLrXvBNmzY163Llyomx9PR0p/Py1nuFHXHHHQAAAAAAAGBDLNwBAAAAAAAANsTCHQAAAAAAAGBDftOwRfc6QWAqVqyYyNHR0dnmjz/+2Cdzgr00a9ZMZN3zBsir+/fvi3z9+nWz7tmzp6+n43d035ry5cuLrHuj6IyC6emnn3aamzdv7sPZwB9s27ZNZP3e0q1bN19OJ+BZ+5fVr19fjOnepePHjxc5LS1N5Pbt25t1jx49xJjuVZiUlCTysWPHRLb2Ok5OThZj1atXFzkmJkbkESNGGMi9qlWriqx71Kempmb73BdeeEHkrl27iqx72lWuXDk3U0QutWzZMtsx3dMyLwKph50r3HEHAAAAAAAA2BALdwAAAAAAAIANsXAHAAAAAAAA2JDf9LgDAMAOgoODRT516lQ+zQQAAkdKSorIN27cEFn3uEP+iYiIEPmzzz4T+e7duyLPmzdP5CNHjpj14MGDxZjucZeYmChyVFSUyH379jXryMhIMdamTRuR9ec78kb/HGRkZOTTTAD/xx13AAAAAAAAgA2xcAcAAAAAAADYEFtlAQAAANia3gqrc506dXw5HeRByZIlRZ4+fXo+zQQA/AN33AEAAAAAAAA2xMIdAAAAAAAAYEMs3AEAAAAAAAA2RI87AAAAALYWGhoq8s8//5xPMwEAwLe44w4AAAAAAACwIRbuAAAAAAAAABti4Q4AAAAAAACwoSCHw+HeE4KCMg3DSPHOdOAhFRwOR4gnD8h59wuc98DEeQ9MnPfA5PHzHhYW5rh8+bInDwkPCwoKSnY4HGGePCbn3f68cd55n/cLfL4HJs57YMrxeXd74Q4AAAAFAxf2foEvdIHJ4+cdAOCfWLgDAAAAAAAAbIgedwAAAAAAAIANsXAHAAAAAAAA2BALdwAAAAAAAIANsXAHAAAAAAAA2BALdwAAAAAAAIANsXAHAAAAAAAA2BALdwAAAAAAAIANsXAHAAAAAAAA2BALdwAAAAAAAIAN/R/vvXlvAwEZpQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1113d9908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 4. 0. 0. 7. 3. 5. 3.]\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,10), dpi=80)\n",
    "shape = (1,10)\n",
    "for j in range(10):\n",
    "    ax = fig.add_subplot(shape[0], shape[1], j+1)\n",
    "    image = train_np_x[j].reshape(28,28)\n",
    "    ax.matshow(image, cmap=matplotlib.cm.binary)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "plt.show()\n",
    "\n",
    "print (train_np_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    x = (x - 0.1307) / 0.3081    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(np.expand_dims(normalize(train_np_x), axis=1))\n",
    "train_y = torch.LongTensor(train_np_y)\n",
    "\n",
    "test_x = torch.Tensor(np.expand_dims(normalize(test_np_x), axis=1))\n",
    "test_y = torch.LongTensor(test_np_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(x, y, batch_size=32):\n",
    "    for i in range(0, x.size(0) - 1, batch_size):\n",
    "        data = x[i:i+batch_size]\n",
    "        if data.shape[0] == batch_size:\n",
    "            data = data.reshape(batch_size, 1, 28, 28)\n",
    "            targets = y[i:i+batch_size]\n",
    "\n",
    "            yield data, targets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, size, padding=1, pool_layer=nn.MaxPool2d(2, stride=2),\n",
    "                 bn=False, dropout=False, activation_fn=nn.ReLU()):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        layers = []        \n",
    "        layers.append(nn.Conv2d(size[0], size[1], size[2], padding=padding))\n",
    "        if pool_layer is not None:\n",
    "            layers.append(pool_layer)\n",
    "        if bn:\n",
    "            layers.append(nn.BatchNorm2d(size[1]))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout2d())\n",
    "        layers.append(activation_fn)\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, sizes, dropout=False, activation_fn=nn.Tanh):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        for i in range(len(sizes) - 2):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
    "            if dropout:\n",
    "                layers.append(nn.Dropout())\n",
    "            layers.append(activation_fn())\n",
    "        else: # нам не нужен дропаут и фнкция активации в последнем слое\n",
    "            layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, batchnorm=False, dropout=False, lr=1e-4, l2=0.):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        \n",
    "        self._conv1 = ConvLayer([1, 16, 3], bn=batchnorm)\n",
    "        self._conv2 = ConvLayer([16, 32, 3], bn=batchnorm, activation_fn=nn.Sigmoid())\n",
    "        \n",
    "        self.fc = FullyConnected([32*7*7, 10], dropout=dropout)\n",
    "        \n",
    "        self._loss = None\n",
    "        self.optim = optim.Adam(self.parameters(), lr=lr, weight_decay=l2)\n",
    "    \n",
    "    def conv(self, x):\n",
    "        x = self._conv1(x)\n",
    "        x = self._conv2(x)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 32*7*7)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, output, target, **kwargs):        \n",
    "        self._loss = F.cross_entropy(output, target, **kwargs)\n",
    "        self._correct = output.data.max(1, keepdim=True)[1]\n",
    "        self._correct = self._correct.eq(target.data.view_as(self._correct)).to(torch.float).cpu().mean()\n",
    "        return self._loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, models, log=None):\n",
    "    train_size = len(train_x)\n",
    "    for batch_idx, (data, target) in enumerate(loader(train_x, train_y)):\n",
    "        for model in models.values():                             \n",
    "            model.optim.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = model.loss(output, target)\n",
    "            loss.backward()\n",
    "            model.optim.step()\n",
    "            \n",
    "        if batch_idx % 200 == 0:\n",
    "            line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "                epoch, batch_idx * len(data), train_size, 100. * batch_idx / train_size)\n",
    "            losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
    "            print(line + losses)\n",
    "            \n",
    "    else:\n",
    "        batch_idx += 1\n",
    "        line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "            epoch, batch_idx * len(data), train_size, 100. * batch_idx / train_size)\n",
    "        losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
    "        if log is not None:\n",
    "            for k in models:\n",
    "                log[k].append((models[k]._loss, models[k]._correct))\n",
    "        print(line + losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, log=None):\n",
    "    test_size = len(test_x)\n",
    "    avg_lambda = lambda l: 'Loss: {:.4f}'.format(l)\n",
    "    acc_lambda = lambda c, p: 'Accuracy: {}/{} ({:.0f}%)'.format(c, test_size, p)\n",
    "    line = lambda i, l, c, p: '{}: '.format(i) + avg_lambda(l) + '\\t' + acc_lambda(c, p)\n",
    "\n",
    "    test_loss = {k: 0. for k in models}\n",
    "    correct = {k: 0. for k in models}\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader(test_x, test_y):\n",
    "            output = {k: m(data) for k, m in models.items()}           \n",
    "            for k, m in models.items():     \n",
    "                #print (output[k].shape, target.shape)\n",
    "                test_loss[k] += m.loss(output[k], target, size_average=False).item() # sum up batch loss\n",
    "                pred = output[k].data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                correct[k] += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "    \n",
    "    for k in models:\n",
    "        test_loss[k] /= test_size\n",
    "    correct_pct = {k: c / test_size for k, c in correct.items()}\n",
    "    lines = '\\n'.join([line(k, test_loss[k], correct[k], 100*correct_pct[k]) for k in models]) + '\\n'\n",
    "    report = 'Test set:\\n' + lines\n",
    "    if log is not None:\n",
    "        for k in models:\n",
    "            log[k].append((test_loss[k], correct_pct[k]))\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(log, tpe='loss'):\n",
    "    keys = log.keys()\n",
    "    logs = {k:[z for z in zip(*log[k])] for k in keys}\n",
    "    epochs = {k:range(len(log[k])) for k in keys}\n",
    " \n",
    "    \n",
    "    if tpe == 'loss':\n",
    "        handlers, = zip(*[plt.plot(epochs[k], logs[k][0], label=k) for k in keys])\n",
    "        plt.title('errors')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('error')\n",
    "        plt.legend(handles=handlers)\n",
    "        plt.show()\n",
    "    elif tpe == 'accuracy':\n",
    "        handlers, = zip(*[plt.plot(epochs[k], logs[k][1], label=k) for k in log.keys()])\n",
    "        plt.title('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.legend(handles=handlers)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'bn': Net(True), 'drop': Net(False, True), 'plain': Net()}\n",
    "train_log = {k: [] for k in models}\n",
    "test_log = {k: [] for k in models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/31500 (0%)]\tLosses bn: 2.319179 drop: 2.357496 plain: 2.348156\n",
      "Train Epoch: 1 [6400/31500 (1%)]\tLosses bn: 1.630361 drop: 2.118411 plain: 2.077665\n",
      "Train Epoch: 1 [12800/31500 (1%)]\tLosses bn: 1.325848 drop: 1.859936 plain: 1.758649\n",
      "Train Epoch: 1 [19200/31500 (2%)]\tLosses bn: 0.824835 drop: 1.160721 plain: 1.058992\n",
      "Train Epoch: 1 [25600/31500 (3%)]\tLosses bn: 0.829483 drop: 1.164378 plain: 1.114301\n",
      "Train Epoch: 1 [31488/31500 (3%)]\tLosses bn: 0.422958 drop: 0.523231 plain: 0.473664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksey/anaconda3/envs/learning/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "bn: Loss: 0.5980\tAccuracy: 9607.0/10500 (91%)\n",
      "drop: Loss: 0.7540\tAccuracy: 8763.0/10500 (83%)\n",
      "plain: Loss: 0.7050\tAccuracy: 8908.0/10500 (85%)\n",
      "\n",
      "Train Epoch: 2 [0/31500 (0%)]\tLosses bn: 0.505012 drop: 0.652800 plain: 0.596863\n",
      "Train Epoch: 2 [6400/31500 (1%)]\tLosses bn: 0.379468 drop: 0.420178 plain: 0.390461\n",
      "Train Epoch: 2 [12800/31500 (1%)]\tLosses bn: 0.507827 drop: 0.684961 plain: 0.656615\n",
      "Train Epoch: 2 [19200/31500 (2%)]\tLosses bn: 0.273590 drop: 0.296539 plain: 0.278426\n",
      "Train Epoch: 2 [25600/31500 (3%)]\tLosses bn: 0.393888 drop: 0.646640 plain: 0.634070\n",
      "Train Epoch: 2 [31488/31500 (3%)]\tLosses bn: 0.190162 drop: 0.246321 plain: 0.225759\n",
      "Test set:\n",
      "bn: Loss: 0.3013\tAccuracy: 9910.0/10500 (94%)\n",
      "drop: Loss: 0.4087\tAccuracy: 9449.0/10500 (90%)\n",
      "plain: Loss: 0.3902\tAccuracy: 9491.0/10500 (90%)\n",
      "\n",
      "Train Epoch: 3 [0/31500 (0%)]\tLosses bn: 0.196939 drop: 0.305009 plain: 0.288510\n",
      "Train Epoch: 3 [6400/31500 (1%)]\tLosses bn: 0.172002 drop: 0.183864 plain: 0.167041\n",
      "Train Epoch: 3 [12800/31500 (1%)]\tLosses bn: 0.311003 drop: 0.536424 plain: 0.523663\n",
      "Train Epoch: 3 [19200/31500 (2%)]\tLosses bn: 0.166262 drop: 0.179024 plain: 0.172245\n",
      "Train Epoch: 3 [25600/31500 (3%)]\tLosses bn: 0.270862 drop: 0.489754 plain: 0.475833\n",
      "Train Epoch: 3 [31488/31500 (3%)]\tLosses bn: 0.123339 drop: 0.173072 plain: 0.157124\n",
      "Test set:\n",
      "bn: Loss: 0.2055\tAccuracy: 10060.0/10500 (96%)\n",
      "drop: Loss: 0.2993\tAccuracy: 9726.0/10500 (93%)\n",
      "plain: Loss: 0.2864\tAccuracy: 9744.0/10500 (93%)\n",
      "\n",
      "Train Epoch: 4 [0/31500 (0%)]\tLosses bn: 0.108288 drop: 0.199863 plain: 0.190700\n",
      "Train Epoch: 4 [6400/31500 (1%)]\tLosses bn: 0.099890 drop: 0.103153 plain: 0.092277\n",
      "Train Epoch: 4 [12800/31500 (1%)]\tLosses bn: 0.220243 drop: 0.469766 plain: 0.457581\n",
      "Train Epoch: 4 [19200/31500 (2%)]\tLosses bn: 0.124093 drop: 0.126062 plain: 0.124492\n",
      "Train Epoch: 4 [25600/31500 (3%)]\tLosses bn: 0.216895 drop: 0.394151 plain: 0.383215\n",
      "Train Epoch: 4 [31488/31500 (3%)]\tLosses bn: 0.091133 drop: 0.136707 plain: 0.126043\n",
      "Test set:\n",
      "bn: Loss: 0.1575\tAccuracy: 10142.0/10500 (97%)\n",
      "drop: Loss: 0.2395\tAccuracy: 9859.0/10500 (94%)\n",
      "plain: Loss: 0.2292\tAccuracy: 9878.0/10500 (94%)\n",
      "\n",
      "Train Epoch: 5 [0/31500 (0%)]\tLosses bn: 0.069985 drop: 0.144583 plain: 0.136708\n",
      "Train Epoch: 5 [6400/31500 (1%)]\tLosses bn: 0.065870 drop: 0.065619 plain: 0.060817\n",
      "Train Epoch: 5 [12800/31500 (1%)]\tLosses bn: 0.168863 drop: 0.416346 plain: 0.403918\n",
      "Train Epoch: 5 [19200/31500 (2%)]\tLosses bn: 0.100780 drop: 0.095825 plain: 0.098181\n",
      "Train Epoch: 5 [25600/31500 (3%)]\tLosses bn: 0.186018 drop: 0.325928 plain: 0.317128\n",
      "Train Epoch: 5 [31488/31500 (3%)]\tLosses bn: 0.071561 drop: 0.114814 plain: 0.108926\n",
      "Test set:\n",
      "bn: Loss: 0.1286\tAccuracy: 10195.0/10500 (97%)\n",
      "drop: Loss: 0.2000\tAccuracy: 9956.0/10500 (95%)\n",
      "plain: Loss: 0.1916\tAccuracy: 9966.0/10500 (95%)\n",
      "\n",
      "Train Epoch: 6 [0/31500 (0%)]\tLosses bn: 0.049503 drop: 0.108761 plain: 0.101151\n",
      "Train Epoch: 6 [6400/31500 (1%)]\tLosses bn: 0.047394 drop: 0.046201 plain: 0.045430\n",
      "Train Epoch: 6 [12800/31500 (1%)]\tLosses bn: 0.136911 drop: 0.364158 plain: 0.356836\n",
      "Train Epoch: 6 [19200/31500 (2%)]\tLosses bn: 0.084525 drop: 0.077282 plain: 0.082373\n",
      "Train Epoch: 6 [25600/31500 (3%)]\tLosses bn: 0.166119 drop: 0.275020 plain: 0.265531\n",
      "Train Epoch: 6 [31488/31500 (3%)]\tLosses bn: 0.057619 drop: 0.100218 plain: 0.097628\n",
      "Test set:\n",
      "bn: Loss: 0.1093\tAccuracy: 10219.0/10500 (97%)\n",
      "drop: Loss: 0.1714\tAccuracy: 10012.0/10500 (95%)\n",
      "plain: Loss: 0.1647\tAccuracy: 10042.0/10500 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/31500 (0%)]\tLosses bn: 0.037161 drop: 0.084087 plain: 0.076247\n",
      "Train Epoch: 7 [6400/31500 (1%)]\tLosses bn: 0.036333 drop: 0.035250 plain: 0.037149\n",
      "Train Epoch: 7 [12800/31500 (1%)]\tLosses bn: 0.115971 drop: 0.316257 plain: 0.314858\n",
      "Train Epoch: 7 [19200/31500 (2%)]\tLosses bn: 0.072668 drop: 0.065490 plain: 0.071450\n",
      "Train Epoch: 7 [25600/31500 (3%)]\tLosses bn: 0.153047 drop: 0.237109 plain: 0.225921\n",
      "Train Epoch: 7 [31488/31500 (3%)]\tLosses bn: 0.047363 drop: 0.090424 plain: 0.088830\n",
      "Test set:\n",
      "bn: Loss: 0.0957\tAccuracy: 10239.0/10500 (98%)\n",
      "drop: Loss: 0.1496\tAccuracy: 10084.0/10500 (96%)\n",
      "plain: Loss: 0.1444\tAccuracy: 10100.0/10500 (96%)\n",
      "\n",
      "Train Epoch: 8 [0/31500 (0%)]\tLosses bn: 0.029192 drop: 0.066790 plain: 0.058623\n",
      "Train Epoch: 8 [6400/31500 (1%)]\tLosses bn: 0.029519 drop: 0.028837 plain: 0.032416\n",
      "Train Epoch: 8 [12800/31500 (1%)]\tLosses bn: 0.102005 drop: 0.274441 plain: 0.277375\n",
      "Train Epoch: 8 [19200/31500 (2%)]\tLosses bn: 0.063559 drop: 0.057837 plain: 0.063866\n",
      "Train Epoch: 8 [25600/31500 (3%)]\tLosses bn: 0.143450 drop: 0.207502 plain: 0.195328\n",
      "Train Epoch: 8 [31488/31500 (3%)]\tLosses bn: 0.039500 drop: 0.083813 plain: 0.081049\n",
      "Test set:\n",
      "bn: Loss: 0.0858\tAccuracy: 10252.0/10500 (98%)\n",
      "drop: Loss: 0.1328\tAccuracy: 10134.0/10500 (97%)\n",
      "plain: Loss: 0.1289\tAccuracy: 10141.0/10500 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/31500 (0%)]\tLosses bn: 0.023626 drop: 0.054054 plain: 0.046329\n",
      "Train Epoch: 9 [6400/31500 (1%)]\tLosses bn: 0.024940 drop: 0.024899 plain: 0.029301\n",
      "Train Epoch: 9 [12800/31500 (1%)]\tLosses bn: 0.092267 drop: 0.239872 plain: 0.244623\n",
      "Train Epoch: 9 [19200/31500 (2%)]\tLosses bn: 0.056500 drop: 0.052420 plain: 0.058734\n",
      "Train Epoch: 9 [25600/31500 (3%)]\tLosses bn: 0.138491 drop: 0.181806 plain: 0.172034\n",
      "Train Epoch: 9 [31488/31500 (3%)]\tLosses bn: 0.033122 drop: 0.078729 plain: 0.074113\n",
      "Test set:\n",
      "bn: Loss: 0.0783\tAccuracy: 10278.0/10500 (98%)\n",
      "drop: Loss: 0.1195\tAccuracy: 10171.0/10500 (97%)\n",
      "plain: Loss: 0.1168\tAccuracy: 10177.0/10500 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/31500 (0%)]\tLosses bn: 0.019874 drop: 0.044616 plain: 0.037506\n",
      "Train Epoch: 10 [6400/31500 (1%)]\tLosses bn: 0.021842 drop: 0.022281 plain: 0.026983\n",
      "Train Epoch: 10 [12800/31500 (1%)]\tLosses bn: 0.085386 drop: 0.211605 plain: 0.217368\n",
      "Train Epoch: 10 [19200/31500 (2%)]\tLosses bn: 0.050633 drop: 0.048147 plain: 0.055151\n",
      "Train Epoch: 10 [25600/31500 (3%)]\tLosses bn: 0.134977 drop: 0.160154 plain: 0.153885\n",
      "Train Epoch: 10 [31488/31500 (3%)]\tLosses bn: 0.028270 drop: 0.074394 plain: 0.068082\n",
      "Test set:\n",
      "bn: Loss: 0.0724\tAccuracy: 10280.0/10500 (98%)\n",
      "drop: Loss: 0.1090\tAccuracy: 10201.0/10500 (97%)\n",
      "plain: Loss: 0.1073\tAccuracy: 10201.0/10500 (97%)\n",
      "\n",
      "Train Epoch: 11 [0/31500 (0%)]\tLosses bn: 0.016904 drop: 0.037672 plain: 0.030928\n",
      "Train Epoch: 11 [6400/31500 (1%)]\tLosses bn: 0.019500 drop: 0.020420 plain: 0.025073\n",
      "Train Epoch: 11 [12800/31500 (1%)]\tLosses bn: 0.080145 drop: 0.188811 plain: 0.195485\n",
      "Train Epoch: 11 [19200/31500 (2%)]\tLosses bn: 0.045817 drop: 0.044641 plain: 0.052186\n",
      "Train Epoch: 11 [25600/31500 (3%)]\tLosses bn: 0.132148 drop: 0.142244 plain: 0.139077\n",
      "Train Epoch: 11 [31488/31500 (3%)]\tLosses bn: 0.024098 drop: 0.070204 plain: 0.062803\n",
      "Test set:\n",
      "bn: Loss: 0.0677\tAccuracy: 10286.0/10500 (98%)\n",
      "drop: Loss: 0.1005\tAccuracy: 10217.0/10500 (97%)\n",
      "plain: Loss: 0.0995\tAccuracy: 10213.0/10500 (97%)\n",
      "\n",
      "Train Epoch: 12 [0/31500 (0%)]\tLosses bn: 0.014686 drop: 0.032446 plain: 0.025887\n",
      "Train Epoch: 12 [6400/31500 (1%)]\tLosses bn: 0.017787 drop: 0.019133 plain: 0.023523\n",
      "Train Epoch: 12 [12800/31500 (1%)]\tLosses bn: 0.075876 drop: 0.170566 plain: 0.178096\n",
      "Train Epoch: 12 [19200/31500 (2%)]\tLosses bn: 0.042592 drop: 0.041563 plain: 0.049667\n",
      "Train Epoch: 12 [25600/31500 (3%)]\tLosses bn: 0.129559 drop: 0.127097 plain: 0.126904\n",
      "Train Epoch: 12 [31488/31500 (3%)]\tLosses bn: 0.020599 drop: 0.066075 plain: 0.058209\n",
      "Test set:\n",
      "bn: Loss: 0.0639\tAccuracy: 10295.0/10500 (98%)\n",
      "drop: Loss: 0.0936\tAccuracy: 10238.0/10500 (98%)\n",
      "plain: Loss: 0.0932\tAccuracy: 10226.0/10500 (97%)\n",
      "\n",
      "Train Epoch: 13 [0/31500 (0%)]\tLosses bn: 0.012869 drop: 0.028654 plain: 0.022129\n",
      "Train Epoch: 13 [6400/31500 (1%)]\tLosses bn: 0.016525 drop: 0.018226 plain: 0.022240\n",
      "Train Epoch: 13 [12800/31500 (1%)]\tLosses bn: 0.071544 drop: 0.155833 plain: 0.164172\n",
      "Train Epoch: 13 [19200/31500 (2%)]\tLosses bn: 0.039714 drop: 0.038913 plain: 0.047359\n",
      "Train Epoch: 13 [25600/31500 (3%)]\tLosses bn: 0.128037 drop: 0.114281 plain: 0.116789\n",
      "Train Epoch: 13 [31488/31500 (3%)]\tLosses bn: 0.017972 drop: 0.062203 plain: 0.054013\n",
      "Test set:\n",
      "bn: Loss: 0.0607\tAccuracy: 10308.0/10500 (98%)\n",
      "drop: Loss: 0.0878\tAccuracy: 10250.0/10500 (98%)\n",
      "plain: Loss: 0.0878\tAccuracy: 10242.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/31500 (0%)]\tLosses bn: 0.011426 drop: 0.025683 plain: 0.019169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [6400/31500 (1%)]\tLosses bn: 0.015319 drop: 0.017511 plain: 0.021090\n",
      "Train Epoch: 14 [12800/31500 (1%)]\tLosses bn: 0.068063 drop: 0.143815 plain: 0.153096\n",
      "Train Epoch: 14 [19200/31500 (2%)]\tLosses bn: 0.037086 drop: 0.036615 plain: 0.045039\n",
      "Train Epoch: 14 [25600/31500 (3%)]\tLosses bn: 0.127183 drop: 0.103556 plain: 0.108167\n",
      "Train Epoch: 14 [31488/31500 (3%)]\tLosses bn: 0.015959 drop: 0.058334 plain: 0.050207\n",
      "Test set:\n",
      "bn: Loss: 0.0580\tAccuracy: 10311.0/10500 (98%)\n",
      "drop: Loss: 0.0830\tAccuracy: 10261.0/10500 (98%)\n",
      "plain: Loss: 0.0833\tAccuracy: 10248.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/31500 (0%)]\tLosses bn: 0.010241 drop: 0.023149 plain: 0.016843\n",
      "Train Epoch: 15 [6400/31500 (1%)]\tLosses bn: 0.014384 drop: 0.016887 plain: 0.020012\n",
      "Train Epoch: 15 [12800/31500 (1%)]\tLosses bn: 0.064825 drop: 0.133849 plain: 0.143902\n",
      "Train Epoch: 15 [19200/31500 (2%)]\tLosses bn: 0.035159 drop: 0.034495 plain: 0.042656\n",
      "Train Epoch: 15 [25600/31500 (3%)]\tLosses bn: 0.127114 drop: 0.094581 plain: 0.100892\n",
      "Train Epoch: 15 [31488/31500 (3%)]\tLosses bn: 0.014047 drop: 0.054378 plain: 0.046819\n",
      "Test set:\n",
      "bn: Loss: 0.0556\tAccuracy: 10314.0/10500 (98%)\n",
      "drop: Loss: 0.0789\tAccuracy: 10267.0/10500 (98%)\n",
      "plain: Loss: 0.0793\tAccuracy: 10259.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/31500 (0%)]\tLosses bn: 0.009312 drop: 0.020977 plain: 0.015004\n",
      "Train Epoch: 16 [6400/31500 (1%)]\tLosses bn: 0.013710 drop: 0.016336 plain: 0.019076\n",
      "Train Epoch: 16 [12800/31500 (1%)]\tLosses bn: 0.061673 drop: 0.125340 plain: 0.135962\n",
      "Train Epoch: 16 [19200/31500 (2%)]\tLosses bn: 0.033498 drop: 0.032563 plain: 0.040370\n",
      "Train Epoch: 16 [25600/31500 (3%)]\tLosses bn: 0.128019 drop: 0.087052 plain: 0.094418\n",
      "Train Epoch: 16 [31488/31500 (3%)]\tLosses bn: 0.012441 drop: 0.050584 plain: 0.043789\n",
      "Test set:\n",
      "bn: Loss: 0.0536\tAccuracy: 10318.0/10500 (98%)\n",
      "drop: Loss: 0.0754\tAccuracy: 10271.0/10500 (98%)\n",
      "plain: Loss: 0.0759\tAccuracy: 10263.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/31500 (0%)]\tLosses bn: 0.008567 drop: 0.018955 plain: 0.013632\n",
      "Train Epoch: 17 [6400/31500 (1%)]\tLosses bn: 0.013005 drop: 0.015819 plain: 0.018343\n",
      "Train Epoch: 17 [12800/31500 (1%)]\tLosses bn: 0.058733 drop: 0.118023 plain: 0.128773\n",
      "Train Epoch: 17 [19200/31500 (2%)]\tLosses bn: 0.031541 drop: 0.030707 plain: 0.038258\n",
      "Train Epoch: 17 [25600/31500 (3%)]\tLosses bn: 0.129039 drop: 0.080904 plain: 0.088737\n",
      "Train Epoch: 17 [31488/31500 (3%)]\tLosses bn: 0.011224 drop: 0.046884 plain: 0.041035\n",
      "Test set:\n",
      "bn: Loss: 0.0519\tAccuracy: 10327.0/10500 (98%)\n",
      "drop: Loss: 0.0723\tAccuracy: 10276.0/10500 (98%)\n",
      "plain: Loss: 0.0729\tAccuracy: 10267.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/31500 (0%)]\tLosses bn: 0.007932 drop: 0.017195 plain: 0.012544\n",
      "Train Epoch: 18 [6400/31500 (1%)]\tLosses bn: 0.012401 drop: 0.015324 plain: 0.017602\n",
      "Train Epoch: 18 [12800/31500 (1%)]\tLosses bn: 0.055416 drop: 0.111570 plain: 0.122072\n",
      "Train Epoch: 18 [19200/31500 (2%)]\tLosses bn: 0.030165 drop: 0.029027 plain: 0.036430\n",
      "Train Epoch: 18 [25600/31500 (3%)]\tLosses bn: 0.129744 drop: 0.075643 plain: 0.083638\n",
      "Train Epoch: 18 [31488/31500 (3%)]\tLosses bn: 0.010290 drop: 0.043335 plain: 0.038659\n",
      "Test set:\n",
      "bn: Loss: 0.0504\tAccuracy: 10330.0/10500 (98%)\n",
      "drop: Loss: 0.0697\tAccuracy: 10284.0/10500 (98%)\n",
      "plain: Loss: 0.0703\tAccuracy: 10278.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/31500 (0%)]\tLosses bn: 0.007334 drop: 0.015722 plain: 0.011611\n",
      "Train Epoch: 19 [6400/31500 (1%)]\tLosses bn: 0.011909 drop: 0.014843 plain: 0.016846\n",
      "Train Epoch: 19 [12800/31500 (1%)]\tLosses bn: 0.052602 drop: 0.105886 plain: 0.115919\n",
      "Train Epoch: 19 [19200/31500 (2%)]\tLosses bn: 0.028385 drop: 0.027520 plain: 0.034726\n",
      "Train Epoch: 19 [25600/31500 (3%)]\tLosses bn: 0.129681 drop: 0.071114 plain: 0.079033\n",
      "Train Epoch: 19 [31488/31500 (3%)]\tLosses bn: 0.009474 drop: 0.039879 plain: 0.036457\n",
      "Test set:\n",
      "bn: Loss: 0.0490\tAccuracy: 10334.0/10500 (98%)\n",
      "drop: Loss: 0.0673\tAccuracy: 10285.0/10500 (98%)\n",
      "plain: Loss: 0.0680\tAccuracy: 10288.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/31500 (0%)]\tLosses bn: 0.006823 drop: 0.014458 plain: 0.010812\n",
      "Train Epoch: 20 [6400/31500 (1%)]\tLosses bn: 0.011456 drop: 0.014371 plain: 0.016113\n",
      "Train Epoch: 20 [12800/31500 (1%)]\tLosses bn: 0.049805 drop: 0.100856 plain: 0.110091\n",
      "Train Epoch: 20 [19200/31500 (2%)]\tLosses bn: 0.027171 drop: 0.026172 plain: 0.033174\n",
      "Train Epoch: 20 [25600/31500 (3%)]\tLosses bn: 0.129861 drop: 0.067105 plain: 0.074894\n",
      "Train Epoch: 20 [31488/31500 (3%)]\tLosses bn: 0.008688 drop: 0.036685 plain: 0.034463\n",
      "Test set:\n",
      "bn: Loss: 0.0478\tAccuracy: 10339.0/10500 (98%)\n",
      "drop: Loss: 0.0652\tAccuracy: 10286.0/10500 (98%)\n",
      "plain: Loss: 0.0659\tAccuracy: 10294.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/31500 (0%)]\tLosses bn: 0.006354 drop: 0.013319 plain: 0.010089\n",
      "Train Epoch: 21 [6400/31500 (1%)]\tLosses bn: 0.011123 drop: 0.013912 plain: 0.015388\n",
      "Train Epoch: 21 [12800/31500 (1%)]\tLosses bn: 0.047529 drop: 0.096399 plain: 0.104507\n",
      "Train Epoch: 21 [19200/31500 (2%)]\tLosses bn: 0.025737 drop: 0.024953 plain: 0.031741\n",
      "Train Epoch: 21 [25600/31500 (3%)]\tLosses bn: 0.129569 drop: 0.063649 plain: 0.071605\n",
      "Train Epoch: 21 [31488/31500 (3%)]\tLosses bn: 0.008119 drop: 0.033847 plain: 0.032612\n",
      "Test set:\n",
      "bn: Loss: 0.0468\tAccuracy: 10340.0/10500 (98%)\n",
      "drop: Loss: 0.0633\tAccuracy: 10293.0/10500 (98%)\n",
      "plain: Loss: 0.0640\tAccuracy: 10305.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/31500 (0%)]\tLosses bn: 0.005978 drop: 0.012347 plain: 0.009438\n",
      "Train Epoch: 22 [6400/31500 (1%)]\tLosses bn: 0.010868 drop: 0.013468 plain: 0.014699\n",
      "Train Epoch: 22 [12800/31500 (1%)]\tLosses bn: 0.044846 drop: 0.092494 plain: 0.099306\n",
      "Train Epoch: 22 [19200/31500 (2%)]\tLosses bn: 0.024408 drop: 0.023890 plain: 0.030384\n",
      "Train Epoch: 22 [25600/31500 (3%)]\tLosses bn: 0.127836 drop: 0.060533 plain: 0.068601\n",
      "Train Epoch: 22 [31488/31500 (3%)]\tLosses bn: 0.007578 drop: 0.031284 plain: 0.030775\n",
      "Test set:\n",
      "bn: Loss: 0.0458\tAccuracy: 10346.0/10500 (99%)\n",
      "drop: Loss: 0.0617\tAccuracy: 10293.0/10500 (98%)\n",
      "plain: Loss: 0.0624\tAccuracy: 10307.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/31500 (0%)]\tLosses bn: 0.005626 drop: 0.011523 plain: 0.008798\n",
      "Train Epoch: 23 [6400/31500 (1%)]\tLosses bn: 0.010556 drop: 0.013040 plain: 0.014087\n",
      "Train Epoch: 23 [12800/31500 (1%)]\tLosses bn: 0.042714 drop: 0.088955 plain: 0.094227\n",
      "Train Epoch: 23 [19200/31500 (2%)]\tLosses bn: 0.023185 drop: 0.022956 plain: 0.029050\n",
      "Train Epoch: 23 [25600/31500 (3%)]\tLosses bn: 0.126123 drop: 0.057767 plain: 0.065973\n",
      "Train Epoch: 23 [31488/31500 (3%)]\tLosses bn: 0.007097 drop: 0.028954 plain: 0.029219\n",
      "Test set:\n",
      "bn: Loss: 0.0450\tAccuracy: 10348.0/10500 (99%)\n",
      "drop: Loss: 0.0601\tAccuracy: 10291.0/10500 (98%)\n",
      "plain: Loss: 0.0609\tAccuracy: 10314.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/31500 (0%)]\tLosses bn: 0.005302 drop: 0.010830 plain: 0.008212\n",
      "Train Epoch: 24 [6400/31500 (1%)]\tLosses bn: 0.010374 drop: 0.012682 plain: 0.013515\n",
      "Train Epoch: 24 [12800/31500 (1%)]\tLosses bn: 0.039985 drop: 0.085666 plain: 0.089390\n",
      "Train Epoch: 24 [19200/31500 (2%)]\tLosses bn: 0.022131 drop: 0.022085 plain: 0.027864\n",
      "Train Epoch: 24 [25600/31500 (3%)]\tLosses bn: 0.124910 drop: 0.055286 plain: 0.063679\n",
      "Train Epoch: 24 [31488/31500 (3%)]\tLosses bn: 0.006644 drop: 0.026838 plain: 0.027695\n",
      "Test set:\n",
      "bn: Loss: 0.0442\tAccuracy: 10350.0/10500 (99%)\n",
      "drop: Loss: 0.0588\tAccuracy: 10296.0/10500 (98%)\n",
      "plain: Loss: 0.0595\tAccuracy: 10314.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/31500 (0%)]\tLosses bn: 0.004955 drop: 0.010234 plain: 0.007687\n",
      "Train Epoch: 25 [6400/31500 (1%)]\tLosses bn: 0.010077 drop: 0.012363 plain: 0.012979\n",
      "Train Epoch: 25 [12800/31500 (1%)]\tLosses bn: 0.037543 drop: 0.082766 plain: 0.084824\n",
      "Train Epoch: 25 [19200/31500 (2%)]\tLosses bn: 0.021039 drop: 0.021241 plain: 0.026667\n",
      "Train Epoch: 25 [25600/31500 (3%)]\tLosses bn: 0.123657 drop: 0.052969 plain: 0.061626\n",
      "Train Epoch: 25 [31488/31500 (3%)]\tLosses bn: 0.006244 drop: 0.025039 plain: 0.026360\n",
      "Test set:\n",
      "bn: Loss: 0.0436\tAccuracy: 10350.0/10500 (99%)\n",
      "drop: Loss: 0.0575\tAccuracy: 10299.0/10500 (98%)\n",
      "plain: Loss: 0.0583\tAccuracy: 10316.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/31500 (0%)]\tLosses bn: 0.004788 drop: 0.009710 plain: 0.007189\n",
      "Train Epoch: 26 [6400/31500 (1%)]\tLosses bn: 0.009793 drop: 0.012083 plain: 0.012524\n",
      "Train Epoch: 26 [12800/31500 (1%)]\tLosses bn: 0.035383 drop: 0.079937 plain: 0.080490\n",
      "Train Epoch: 26 [19200/31500 (2%)]\tLosses bn: 0.019952 drop: 0.020512 plain: 0.025570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 [25600/31500 (3%)]\tLosses bn: 0.120502 drop: 0.050954 plain: 0.059729\n",
      "Train Epoch: 26 [31488/31500 (3%)]\tLosses bn: 0.005867 drop: 0.023386 plain: 0.025043\n",
      "Test set:\n",
      "bn: Loss: 0.0429\tAccuracy: 10355.0/10500 (99%)\n",
      "drop: Loss: 0.0564\tAccuracy: 10305.0/10500 (98%)\n",
      "plain: Loss: 0.0571\tAccuracy: 10317.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/31500 (0%)]\tLosses bn: 0.004566 drop: 0.009251 plain: 0.006739\n",
      "Train Epoch: 27 [6400/31500 (1%)]\tLosses bn: 0.009685 drop: 0.011820 plain: 0.012080\n",
      "Train Epoch: 27 [12800/31500 (1%)]\tLosses bn: 0.032983 drop: 0.077237 plain: 0.076301\n",
      "Train Epoch: 27 [19200/31500 (2%)]\tLosses bn: 0.018893 drop: 0.019894 plain: 0.024502\n",
      "Train Epoch: 27 [25600/31500 (3%)]\tLosses bn: 0.118459 drop: 0.049108 plain: 0.057954\n",
      "Train Epoch: 27 [31488/31500 (3%)]\tLosses bn: 0.005548 drop: 0.021834 plain: 0.023836\n",
      "Test set:\n",
      "bn: Loss: 0.0424\tAccuracy: 10357.0/10500 (99%)\n",
      "drop: Loss: 0.0553\tAccuracy: 10310.0/10500 (98%)\n",
      "plain: Loss: 0.0561\tAccuracy: 10320.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/31500 (0%)]\tLosses bn: 0.004385 drop: 0.008849 plain: 0.006337\n",
      "Train Epoch: 28 [6400/31500 (1%)]\tLosses bn: 0.009251 drop: 0.011553 plain: 0.011677\n",
      "Train Epoch: 28 [12800/31500 (1%)]\tLosses bn: 0.030624 drop: 0.074550 plain: 0.072266\n",
      "Train Epoch: 28 [19200/31500 (2%)]\tLosses bn: 0.018291 drop: 0.019333 plain: 0.023511\n",
      "Train Epoch: 28 [25600/31500 (3%)]\tLosses bn: 0.115734 drop: 0.047477 plain: 0.056264\n",
      "Train Epoch: 28 [31488/31500 (3%)]\tLosses bn: 0.005225 drop: 0.020390 plain: 0.022700\n",
      "Test set:\n",
      "bn: Loss: 0.0419\tAccuracy: 10356.0/10500 (99%)\n",
      "drop: Loss: 0.0543\tAccuracy: 10314.0/10500 (98%)\n",
      "plain: Loss: 0.0552\tAccuracy: 10323.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/31500 (0%)]\tLosses bn: 0.004270 drop: 0.008480 plain: 0.005979\n",
      "Train Epoch: 29 [6400/31500 (1%)]\tLosses bn: 0.008978 drop: 0.011313 plain: 0.011346\n",
      "Train Epoch: 29 [12800/31500 (1%)]\tLosses bn: 0.029014 drop: 0.071997 plain: 0.068359\n",
      "Train Epoch: 29 [19200/31500 (2%)]\tLosses bn: 0.017355 drop: 0.018845 plain: 0.022579\n",
      "Train Epoch: 29 [25600/31500 (3%)]\tLosses bn: 0.112995 drop: 0.045985 plain: 0.054771\n",
      "Train Epoch: 29 [31488/31500 (3%)]\tLosses bn: 0.005051 drop: 0.019045 plain: 0.021640\n",
      "Test set:\n",
      "bn: Loss: 0.0414\tAccuracy: 10359.0/10500 (99%)\n",
      "drop: Loss: 0.0534\tAccuracy: 10320.0/10500 (98%)\n",
      "plain: Loss: 0.0543\tAccuracy: 10325.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/31500 (0%)]\tLosses bn: 0.004064 drop: 0.008152 plain: 0.005676\n",
      "Train Epoch: 30 [6400/31500 (1%)]\tLosses bn: 0.008544 drop: 0.011068 plain: 0.011019\n",
      "Train Epoch: 30 [12800/31500 (1%)]\tLosses bn: 0.026875 drop: 0.069417 plain: 0.064645\n",
      "Train Epoch: 30 [19200/31500 (2%)]\tLosses bn: 0.016680 drop: 0.018345 plain: 0.021690\n",
      "Train Epoch: 30 [25600/31500 (3%)]\tLosses bn: 0.109149 drop: 0.044546 plain: 0.053295\n",
      "Train Epoch: 30 [31488/31500 (3%)]\tLosses bn: 0.004837 drop: 0.017860 plain: 0.020670\n",
      "Test set:\n",
      "bn: Loss: 0.0411\tAccuracy: 10360.0/10500 (99%)\n",
      "drop: Loss: 0.0526\tAccuracy: 10324.0/10500 (98%)\n",
      "plain: Loss: 0.0535\tAccuracy: 10324.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/31500 (0%)]\tLosses bn: 0.003957 drop: 0.007819 plain: 0.005419\n",
      "Train Epoch: 31 [6400/31500 (1%)]\tLosses bn: 0.008255 drop: 0.010806 plain: 0.010762\n",
      "Train Epoch: 31 [12800/31500 (1%)]\tLosses bn: 0.025225 drop: 0.066991 plain: 0.061067\n",
      "Train Epoch: 31 [19200/31500 (2%)]\tLosses bn: 0.015957 drop: 0.017967 plain: 0.020879\n",
      "Train Epoch: 31 [25600/31500 (3%)]\tLosses bn: 0.104647 drop: 0.043250 plain: 0.052041\n",
      "Train Epoch: 31 [31488/31500 (3%)]\tLosses bn: 0.004580 drop: 0.016806 plain: 0.019756\n",
      "Test set:\n",
      "bn: Loss: 0.0406\tAccuracy: 10359.0/10500 (99%)\n",
      "drop: Loss: 0.0518\tAccuracy: 10327.0/10500 (98%)\n",
      "plain: Loss: 0.0527\tAccuracy: 10325.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 32 [0/31500 (0%)]\tLosses bn: 0.003794 drop: 0.007513 plain: 0.005197\n",
      "Train Epoch: 32 [6400/31500 (1%)]\tLosses bn: 0.008018 drop: 0.010540 plain: 0.010495\n",
      "Train Epoch: 32 [12800/31500 (1%)]\tLosses bn: 0.023310 drop: 0.064596 plain: 0.057799\n",
      "Train Epoch: 32 [19200/31500 (2%)]\tLosses bn: 0.015324 drop: 0.017597 plain: 0.020116\n",
      "Train Epoch: 32 [25600/31500 (3%)]\tLosses bn: 0.101412 drop: 0.042058 plain: 0.050853\n",
      "Train Epoch: 32 [31488/31500 (3%)]\tLosses bn: 0.004437 drop: 0.015804 plain: 0.018907\n",
      "Test set:\n",
      "bn: Loss: 0.0402\tAccuracy: 10361.0/10500 (99%)\n",
      "drop: Loss: 0.0511\tAccuracy: 10334.0/10500 (98%)\n",
      "plain: Loss: 0.0520\tAccuracy: 10326.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/31500 (0%)]\tLosses bn: 0.003633 drop: 0.007236 plain: 0.004979\n",
      "Train Epoch: 33 [6400/31500 (1%)]\tLosses bn: 0.007685 drop: 0.010301 plain: 0.010305\n",
      "Train Epoch: 33 [12800/31500 (1%)]\tLosses bn: 0.022018 drop: 0.062298 plain: 0.054617\n",
      "Train Epoch: 33 [19200/31500 (2%)]\tLosses bn: 0.014588 drop: 0.017309 plain: 0.019398\n",
      "Train Epoch: 33 [25600/31500 (3%)]\tLosses bn: 0.097166 drop: 0.040894 plain: 0.049688\n",
      "Train Epoch: 33 [31488/31500 (3%)]\tLosses bn: 0.004233 drop: 0.014856 plain: 0.018114\n",
      "Test set:\n",
      "bn: Loss: 0.0400\tAccuracy: 10360.0/10500 (99%)\n",
      "drop: Loss: 0.0504\tAccuracy: 10333.0/10500 (98%)\n",
      "plain: Loss: 0.0514\tAccuracy: 10326.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/31500 (0%)]\tLosses bn: 0.003518 drop: 0.007003 plain: 0.004788\n",
      "Train Epoch: 34 [6400/31500 (1%)]\tLosses bn: 0.007567 drop: 0.010055 plain: 0.010078\n",
      "Train Epoch: 34 [12800/31500 (1%)]\tLosses bn: 0.020829 drop: 0.060068 plain: 0.051552\n",
      "Train Epoch: 34 [19200/31500 (2%)]\tLosses bn: 0.014022 drop: 0.017013 plain: 0.018746\n",
      "Train Epoch: 34 [25600/31500 (3%)]\tLosses bn: 0.092348 drop: 0.039839 plain: 0.048634\n",
      "Train Epoch: 34 [31488/31500 (3%)]\tLosses bn: 0.004120 drop: 0.013980 plain: 0.017348\n",
      "Test set:\n",
      "bn: Loss: 0.0397\tAccuracy: 10362.0/10500 (99%)\n",
      "drop: Loss: 0.0498\tAccuracy: 10336.0/10500 (98%)\n",
      "plain: Loss: 0.0508\tAccuracy: 10329.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/31500 (0%)]\tLosses bn: 0.003416 drop: 0.006797 plain: 0.004634\n",
      "Train Epoch: 35 [6400/31500 (1%)]\tLosses bn: 0.007281 drop: 0.009832 plain: 0.009882\n",
      "Train Epoch: 35 [12800/31500 (1%)]\tLosses bn: 0.019640 drop: 0.058001 plain: 0.048653\n",
      "Train Epoch: 35 [19200/31500 (2%)]\tLosses bn: 0.013512 drop: 0.016731 plain: 0.018120\n",
      "Train Epoch: 35 [25600/31500 (3%)]\tLosses bn: 0.089191 drop: 0.038747 plain: 0.047700\n",
      "Train Epoch: 35 [31488/31500 (3%)]\tLosses bn: 0.003962 drop: 0.013188 plain: 0.016665\n",
      "Test set:\n",
      "bn: Loss: 0.0395\tAccuracy: 10362.0/10500 (99%)\n",
      "drop: Loss: 0.0492\tAccuracy: 10336.0/10500 (98%)\n",
      "plain: Loss: 0.0503\tAccuracy: 10331.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/31500 (0%)]\tLosses bn: 0.003273 drop: 0.006567 plain: 0.004479\n",
      "Train Epoch: 36 [6400/31500 (1%)]\tLosses bn: 0.007173 drop: 0.009603 plain: 0.009674\n",
      "Train Epoch: 36 [12800/31500 (1%)]\tLosses bn: 0.018584 drop: 0.055945 plain: 0.045872\n",
      "Train Epoch: 36 [19200/31500 (2%)]\tLosses bn: 0.013063 drop: 0.016480 plain: 0.017529\n",
      "Train Epoch: 36 [25600/31500 (3%)]\tLosses bn: 0.085165 drop: 0.037800 plain: 0.046750\n",
      "Train Epoch: 36 [31488/31500 (3%)]\tLosses bn: 0.003865 drop: 0.012496 plain: 0.016026\n",
      "Test set:\n",
      "bn: Loss: 0.0392\tAccuracy: 10362.0/10500 (99%)\n",
      "drop: Loss: 0.0487\tAccuracy: 10339.0/10500 (98%)\n",
      "plain: Loss: 0.0498\tAccuracy: 10331.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 37 [0/31500 (0%)]\tLosses bn: 0.003207 drop: 0.006357 plain: 0.004353\n",
      "Train Epoch: 37 [6400/31500 (1%)]\tLosses bn: 0.007063 drop: 0.009349 plain: 0.009501\n",
      "Train Epoch: 37 [12800/31500 (1%)]\tLosses bn: 0.017753 drop: 0.054045 plain: 0.043198\n",
      "Train Epoch: 37 [19200/31500 (2%)]\tLosses bn: 0.012554 drop: 0.016168 plain: 0.016988\n",
      "Train Epoch: 37 [25600/31500 (3%)]\tLosses bn: 0.081342 drop: 0.036903 plain: 0.045933\n",
      "Train Epoch: 37 [31488/31500 (3%)]\tLosses bn: 0.003694 drop: 0.011867 plain: 0.015408\n",
      "Test set:\n",
      "bn: Loss: 0.0390\tAccuracy: 10362.0/10500 (99%)\n",
      "drop: Loss: 0.0482\tAccuracy: 10341.0/10500 (98%)\n",
      "plain: Loss: 0.0493\tAccuracy: 10331.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 38 [0/31500 (0%)]\tLosses bn: 0.003075 drop: 0.006175 plain: 0.004239\n",
      "Train Epoch: 38 [6400/31500 (1%)]\tLosses bn: 0.006990 drop: 0.009121 plain: 0.009330\n",
      "Train Epoch: 38 [12800/31500 (1%)]\tLosses bn: 0.016563 drop: 0.052157 plain: 0.040762\n",
      "Train Epoch: 38 [19200/31500 (2%)]\tLosses bn: 0.012146 drop: 0.015923 plain: 0.016480\n",
      "Train Epoch: 38 [25600/31500 (3%)]\tLosses bn: 0.076251 drop: 0.036020 plain: 0.045074\n",
      "Train Epoch: 38 [31488/31500 (3%)]\tLosses bn: 0.003543 drop: 0.011302 plain: 0.014848\n",
      "Test set:\n",
      "bn: Loss: 0.0389\tAccuracy: 10364.0/10500 (99%)\n",
      "drop: Loss: 0.0477\tAccuracy: 10341.0/10500 (98%)\n",
      "plain: Loss: 0.0488\tAccuracy: 10331.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 39 [0/31500 (0%)]\tLosses bn: 0.002958 drop: 0.006010 plain: 0.004126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 39 [6400/31500 (1%)]\tLosses bn: 0.006785 drop: 0.008914 plain: 0.009175\n",
      "Train Epoch: 39 [12800/31500 (1%)]\tLosses bn: 0.015598 drop: 0.050268 plain: 0.038398\n",
      "Train Epoch: 39 [19200/31500 (2%)]\tLosses bn: 0.011783 drop: 0.015697 plain: 0.015988\n",
      "Train Epoch: 39 [25600/31500 (3%)]\tLosses bn: 0.070991 drop: 0.035209 plain: 0.044203\n",
      "Train Epoch: 39 [31488/31500 (3%)]\tLosses bn: 0.003357 drop: 0.010771 plain: 0.014278\n",
      "Test set:\n",
      "bn: Loss: 0.0387\tAccuracy: 10365.0/10500 (99%)\n",
      "drop: Loss: 0.0472\tAccuracy: 10344.0/10500 (99%)\n",
      "plain: Loss: 0.0484\tAccuracy: 10331.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/31500 (0%)]\tLosses bn: 0.002848 drop: 0.005830 plain: 0.004034\n",
      "Train Epoch: 40 [6400/31500 (1%)]\tLosses bn: 0.006627 drop: 0.008696 plain: 0.008984\n",
      "Train Epoch: 40 [12800/31500 (1%)]\tLosses bn: 0.014696 drop: 0.048471 plain: 0.036233\n",
      "Train Epoch: 40 [19200/31500 (2%)]\tLosses bn: 0.011211 drop: 0.015451 plain: 0.015550\n",
      "Train Epoch: 40 [25600/31500 (3%)]\tLosses bn: 0.066656 drop: 0.034367 plain: 0.043293\n",
      "Train Epoch: 40 [31488/31500 (3%)]\tLosses bn: 0.003186 drop: 0.010292 plain: 0.013756\n",
      "Test set:\n",
      "bn: Loss: 0.0386\tAccuracy: 10364.0/10500 (99%)\n",
      "drop: Loss: 0.0468\tAccuracy: 10344.0/10500 (99%)\n",
      "plain: Loss: 0.0480\tAccuracy: 10334.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 41 [0/31500 (0%)]\tLosses bn: 0.002727 drop: 0.005666 plain: 0.003942\n",
      "Train Epoch: 41 [6400/31500 (1%)]\tLosses bn: 0.006462 drop: 0.008485 plain: 0.008840\n",
      "Train Epoch: 41 [12800/31500 (1%)]\tLosses bn: 0.013636 drop: 0.046704 plain: 0.034114\n",
      "Train Epoch: 41 [19200/31500 (2%)]\tLosses bn: 0.011035 drop: 0.015190 plain: 0.015075\n",
      "Train Epoch: 41 [25600/31500 (3%)]\tLosses bn: 0.061931 drop: 0.033513 plain: 0.042531\n",
      "Train Epoch: 41 [31488/31500 (3%)]\tLosses bn: 0.002992 drop: 0.009823 plain: 0.013225\n",
      "Test set:\n",
      "bn: Loss: 0.0385\tAccuracy: 10365.0/10500 (99%)\n",
      "drop: Loss: 0.0464\tAccuracy: 10348.0/10500 (99%)\n",
      "plain: Loss: 0.0476\tAccuracy: 10336.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 42 [0/31500 (0%)]\tLosses bn: 0.002570 drop: 0.005494 plain: 0.003860\n",
      "Train Epoch: 42 [6400/31500 (1%)]\tLosses bn: 0.006272 drop: 0.008269 plain: 0.008663\n",
      "Train Epoch: 42 [12800/31500 (1%)]\tLosses bn: 0.012827 drop: 0.044964 plain: 0.032168\n",
      "Train Epoch: 42 [19200/31500 (2%)]\tLosses bn: 0.010603 drop: 0.014927 plain: 0.014684\n",
      "Train Epoch: 42 [25600/31500 (3%)]\tLosses bn: 0.057410 drop: 0.032781 plain: 0.041641\n",
      "Train Epoch: 42 [31488/31500 (3%)]\tLosses bn: 0.002855 drop: 0.009364 plain: 0.012755\n",
      "Test set:\n",
      "bn: Loss: 0.0384\tAccuracy: 10362.0/10500 (99%)\n",
      "drop: Loss: 0.0460\tAccuracy: 10347.0/10500 (99%)\n",
      "plain: Loss: 0.0473\tAccuracy: 10336.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 43 [0/31500 (0%)]\tLosses bn: 0.002400 drop: 0.005333 plain: 0.003788\n",
      "Train Epoch: 43 [6400/31500 (1%)]\tLosses bn: 0.006065 drop: 0.008069 plain: 0.008501\n",
      "Train Epoch: 43 [12800/31500 (1%)]\tLosses bn: 0.011929 drop: 0.043233 plain: 0.030203\n",
      "Train Epoch: 43 [19200/31500 (2%)]\tLosses bn: 0.010135 drop: 0.014693 plain: 0.014304\n",
      "Train Epoch: 43 [25600/31500 (3%)]\tLosses bn: 0.052235 drop: 0.032059 plain: 0.040736\n",
      "Train Epoch: 43 [31488/31500 (3%)]\tLosses bn: 0.002736 drop: 0.008931 plain: 0.012264\n",
      "Test set:\n",
      "bn: Loss: 0.0383\tAccuracy: 10362.0/10500 (99%)\n",
      "drop: Loss: 0.0456\tAccuracy: 10345.0/10500 (99%)\n",
      "plain: Loss: 0.0470\tAccuracy: 10337.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 44 [0/31500 (0%)]\tLosses bn: 0.002271 drop: 0.005183 plain: 0.003711\n",
      "Train Epoch: 44 [6400/31500 (1%)]\tLosses bn: 0.005802 drop: 0.007882 plain: 0.008347\n",
      "Train Epoch: 44 [12800/31500 (1%)]\tLosses bn: 0.011015 drop: 0.041585 plain: 0.028424\n",
      "Train Epoch: 44 [19200/31500 (2%)]\tLosses bn: 0.009938 drop: 0.014451 plain: 0.013966\n",
      "Train Epoch: 44 [25600/31500 (3%)]\tLosses bn: 0.047451 drop: 0.031341 plain: 0.039836\n",
      "Train Epoch: 44 [31488/31500 (3%)]\tLosses bn: 0.002630 drop: 0.008550 plain: 0.011814\n",
      "Test set:\n",
      "bn: Loss: 0.0382\tAccuracy: 10360.0/10500 (99%)\n",
      "drop: Loss: 0.0453\tAccuracy: 10346.0/10500 (99%)\n",
      "plain: Loss: 0.0466\tAccuracy: 10339.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 45 [0/31500 (0%)]\tLosses bn: 0.002128 drop: 0.005036 plain: 0.003640\n",
      "Train Epoch: 45 [6400/31500 (1%)]\tLosses bn: 0.005599 drop: 0.007700 plain: 0.008168\n",
      "Train Epoch: 45 [12800/31500 (1%)]\tLosses bn: 0.010286 drop: 0.039963 plain: 0.026831\n",
      "Train Epoch: 45 [19200/31500 (2%)]\tLosses bn: 0.009621 drop: 0.014224 plain: 0.013612\n",
      "Train Epoch: 45 [25600/31500 (3%)]\tLosses bn: 0.044349 drop: 0.030658 plain: 0.039079\n",
      "Train Epoch: 45 [31488/31500 (3%)]\tLosses bn: 0.002522 drop: 0.008174 plain: 0.011377\n",
      "Test set:\n",
      "bn: Loss: 0.0382\tAccuracy: 10362.0/10500 (99%)\n",
      "drop: Loss: 0.0450\tAccuracy: 10345.0/10500 (99%)\n",
      "plain: Loss: 0.0463\tAccuracy: 10340.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 46 [0/31500 (0%)]\tLosses bn: 0.002084 drop: 0.004907 plain: 0.003578\n",
      "Train Epoch: 46 [6400/31500 (1%)]\tLosses bn: 0.005330 drop: 0.007512 plain: 0.007998\n",
      "Train Epoch: 46 [12800/31500 (1%)]\tLosses bn: 0.009553 drop: 0.038482 plain: 0.025321\n",
      "Train Epoch: 46 [19200/31500 (2%)]\tLosses bn: 0.009381 drop: 0.014005 plain: 0.013243\n",
      "Train Epoch: 46 [25600/31500 (3%)]\tLosses bn: 0.039517 drop: 0.029966 plain: 0.038234\n",
      "Train Epoch: 46 [31488/31500 (3%)]\tLosses bn: 0.002360 drop: 0.007848 plain: 0.010971\n",
      "Test set:\n",
      "bn: Loss: 0.0381\tAccuracy: 10361.0/10500 (99%)\n",
      "drop: Loss: 0.0446\tAccuracy: 10345.0/10500 (99%)\n",
      "plain: Loss: 0.0460\tAccuracy: 10340.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 47 [0/31500 (0%)]\tLosses bn: 0.001990 drop: 0.004769 plain: 0.003513\n",
      "Train Epoch: 47 [6400/31500 (1%)]\tLosses bn: 0.005206 drop: 0.007335 plain: 0.007857\n",
      "Train Epoch: 47 [12800/31500 (1%)]\tLosses bn: 0.008969 drop: 0.037038 plain: 0.023930\n",
      "Train Epoch: 47 [19200/31500 (2%)]\tLosses bn: 0.009109 drop: 0.013765 plain: 0.012892\n",
      "Train Epoch: 47 [25600/31500 (3%)]\tLosses bn: 0.035870 drop: 0.029256 plain: 0.037492\n",
      "Train Epoch: 47 [31488/31500 (3%)]\tLosses bn: 0.002282 drop: 0.007522 plain: 0.010562\n",
      "Test set:\n",
      "bn: Loss: 0.0381\tAccuracy: 10361.0/10500 (99%)\n",
      "drop: Loss: 0.0444\tAccuracy: 10344.0/10500 (99%)\n",
      "plain: Loss: 0.0458\tAccuracy: 10341.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 48 [0/31500 (0%)]\tLosses bn: 0.001905 drop: 0.004631 plain: 0.003444\n",
      "Train Epoch: 48 [6400/31500 (1%)]\tLosses bn: 0.005037 drop: 0.007199 plain: 0.007695\n",
      "Train Epoch: 48 [12800/31500 (1%)]\tLosses bn: 0.008316 drop: 0.035697 plain: 0.022689\n",
      "Train Epoch: 48 [19200/31500 (2%)]\tLosses bn: 0.008862 drop: 0.013560 plain: 0.012574\n",
      "Train Epoch: 48 [25600/31500 (3%)]\tLosses bn: 0.032715 drop: 0.028583 plain: 0.036649\n",
      "Train Epoch: 48 [31488/31500 (3%)]\tLosses bn: 0.002170 drop: 0.007239 plain: 0.010197\n",
      "Test set:\n",
      "bn: Loss: 0.0380\tAccuracy: 10361.0/10500 (99%)\n",
      "drop: Loss: 0.0441\tAccuracy: 10344.0/10500 (99%)\n",
      "plain: Loss: 0.0455\tAccuracy: 10341.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 49 [0/31500 (0%)]\tLosses bn: 0.001793 drop: 0.004518 plain: 0.003386\n",
      "Train Epoch: 49 [6400/31500 (1%)]\tLosses bn: 0.004799 drop: 0.007052 plain: 0.007541\n",
      "Train Epoch: 49 [12800/31500 (1%)]\tLosses bn: 0.008003 drop: 0.034355 plain: 0.021502\n",
      "Train Epoch: 49 [19200/31500 (2%)]\tLosses bn: 0.008653 drop: 0.013348 plain: 0.012295\n",
      "Train Epoch: 49 [25600/31500 (3%)]\tLosses bn: 0.029690 drop: 0.027958 plain: 0.035971\n",
      "Train Epoch: 49 [31488/31500 (3%)]\tLosses bn: 0.002063 drop: 0.006959 plain: 0.009816\n",
      "Test set:\n",
      "bn: Loss: 0.0380\tAccuracy: 10362.0/10500 (99%)\n",
      "drop: Loss: 0.0438\tAccuracy: 10347.0/10500 (99%)\n",
      "plain: Loss: 0.0453\tAccuracy: 10341.0/10500 (98%)\n",
      "\n",
      "Train Epoch: 50 [0/31500 (0%)]\tLosses bn: 0.001806 drop: 0.004400 plain: 0.003319\n",
      "Train Epoch: 50 [6400/31500 (1%)]\tLosses bn: 0.004586 drop: 0.006895 plain: 0.007382\n",
      "Train Epoch: 50 [12800/31500 (1%)]\tLosses bn: 0.007159 drop: 0.033072 plain: 0.020431\n",
      "Train Epoch: 50 [19200/31500 (2%)]\tLosses bn: 0.007868 drop: 0.013137 plain: 0.012027\n",
      "Train Epoch: 50 [25600/31500 (3%)]\tLosses bn: 0.026673 drop: 0.027328 plain: 0.035242\n",
      "Train Epoch: 50 [31488/31500 (3%)]\tLosses bn: 0.001969 drop: 0.006700 plain: 0.009449\n",
      "Test set:\n",
      "bn: Loss: 0.0380\tAccuracy: 10363.0/10500 (99%)\n",
      "drop: Loss: 0.0436\tAccuracy: 10347.0/10500 (99%)\n",
      "plain: Loss: 0.0450\tAccuracy: 10341.0/10500 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "    for model in models.values():\n",
    "        model.train()\n",
    "    train(epoch, models, train_log)\n",
    "    for model in models.values():\n",
    "        model.eval()\n",
    "    test(models, test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x160b796d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(test_log, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x160b79be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(test_log, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Расчет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('./test.csv', delimiter=',')\n",
    "data = np.delete(data, (0), axis=0)\n",
    "data_np_x = data / 255\n",
    "\n",
    "testing_x = torch.Tensor(np.expand_dims(normalize(data_np_x), axis=1))\n",
    "testing_y = torch.LongTensor(np.zeros((testing_x.shape[0], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28000, 1, 784])\n"
     ]
    }
   ],
   "source": [
    "print (testing_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (_conv1): ConvLayer(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (_conv2): ConvLayer(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (fc): FullyConnected(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=1568, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "(28000, 10)\n"
     ]
    }
   ],
   "source": [
    "answers = np.empty((0, 10))\n",
    "model = models['bn']\n",
    "print (model)\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(loader(testing_x, testing_y)):\n",
    "    output = model(data)  \n",
    "    output_np = output.detach().numpy()        \n",
    "    answers = np.vstack((answers, output_np))\n",
    "        \n",
    "print (answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.argmax(answers, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.12488651e+00 -1.16979609e+01  1.17131557e+01 -5.37578058e+00\n",
      "  -8.31176376e+00 -1.09081621e+01 -1.34402914e+01 -4.28746128e+00\n",
      "  -7.84575081e+00 -1.00317526e+01]\n",
      " [ 6.96432972e+00 -1.35306473e+01 -3.80551410e+00 -7.74131393e+00\n",
      "  -1.45859861e+01 -2.54134369e+00 -4.08026028e+00 -6.29842377e+00\n",
      "  -7.99108171e+00 -9.28692245e+00]\n",
      " [-1.35510426e+01 -1.14046307e+01 -7.60599947e+00 -7.64140844e+00\n",
      "   4.67250943e-02 -9.16571903e+00 -1.28538885e+01 -6.83837461e+00\n",
      "  -4.51762295e+00  8.58169079e+00]\n",
      " [ 1.72356701e+00 -1.55118017e+01 -1.08282626e+00 -4.59631681e+00\n",
      "  -7.06376934e+00 -7.98744965e+00 -7.97513676e+00 -1.46969581e+00\n",
      "  -9.23403740e+00 -1.17659724e+00]\n",
      " [-7.34492588e+00 -1.17528381e+01 -6.07341170e-01  4.36626577e+00\n",
      "  -1.14333391e+01 -7.63504934e+00 -1.01330757e+01 -7.76082563e+00\n",
      "  -1.51367474e+00 -7.65570545e+00]\n",
      " [-1.04503775e+01 -1.17438173e+01 -4.93470144e+00 -5.25151157e+00\n",
      "  -5.87223005e+00 -5.37248993e+00 -1.39909563e+01  5.12942410e+00\n",
      "  -9.35096073e+00 -2.54206133e+00]\n",
      " [ 1.20198565e+01 -1.18189993e+01 -8.35671961e-01 -1.05061092e+01\n",
      "  -6.71283770e+00 -9.14713383e+00 -1.78471053e+00 -1.00456600e+01\n",
      "  -5.74962091e+00 -5.85326862e+00]\n",
      " [-8.42424774e+00 -1.08642464e+01 -4.66187859e+00  8.90144444e+00\n",
      "  -9.42489624e+00 -2.96895027e+00 -1.69051323e+01 -4.12678909e+00\n",
      "  -1.06836796e+01 -1.68232119e+00]\n",
      " [ 9.74047565e+00 -1.50821352e+01 -3.34314966e+00 -5.47240400e+00\n",
      "  -1.55022335e+01 -4.28364563e+00 -3.35043168e+00 -9.23915577e+00\n",
      "  -7.32918072e+00 -2.64836812e+00]\n",
      " [-1.52537241e+01 -1.55347900e+01 -7.44650078e+00  1.14715548e+01\n",
      "  -1.32965984e+01 -1.65712476e-01 -9.05488300e+00 -7.37407351e+00\n",
      "  -4.42537117e+00 -5.71616030e+00]\n",
      " [-1.29129324e+01 -1.75051594e+01 -1.41386929e+01 -4.80793667e+00\n",
      "  -8.42381001e+00  1.17257872e+01 -6.98013926e+00 -1.09461946e+01\n",
      "  -2.00507617e+00 -4.41648901e-01]\n",
      " [-7.58386993e+00 -6.32420254e+00  1.93239415e+00 -3.44962907e+00\n",
      "  -7.88437271e+00 -1.37222900e+01 -1.91532784e+01  8.03279686e+00\n",
      "  -8.76445198e+00 -1.47411358e+00]\n",
      " [-1.37189770e+01 -6.88357258e+00 -9.94536972e+00 -6.50455189e+00\n",
      "   4.93032837e+00 -1.66353834e+00 -1.32644596e+01 -4.79434490e+00\n",
      "  -4.65954399e+00 -1.12157726e+00]\n",
      " [ 1.22825823e+01 -1.57905264e+01 -4.02733135e+00 -6.65916729e+00\n",
      "  -1.54532070e+01 -4.82826614e+00 -1.03619182e+00 -9.42788029e+00\n",
      "  -6.58368397e+00 -4.10773849e+00]\n",
      " [-1.35694656e+01 -7.38352013e+00 -9.63653564e+00 -9.32181454e+00\n",
      "   8.70352268e+00 -1.17309217e+01 -1.13667383e+01 -1.00735688e+00\n",
      "  -4.48537683e+00 -3.83845001e-01]\n",
      " [-8.24456406e+00 -8.50318146e+00 -6.52212667e+00  4.70660973e+00\n",
      "  -1.05441360e+01 -3.42880487e-02 -1.03463612e+01 -8.43045712e+00\n",
      "  -7.58237219e+00 -9.39562416e+00]\n",
      " [-9.77350235e+00 -9.47426796e+00 -5.06275368e+00  6.89343357e+00\n",
      "  -1.27699223e+01 -2.99973893e+00 -9.51857471e+00 -7.50605345e+00\n",
      "  -7.93953228e+00 -6.51233101e+00]\n",
      " [-6.67477131e+00  8.34907627e+00 -5.72173214e+00 -9.63694096e+00\n",
      "  -1.03833568e+00 -5.40815973e+00 -5.06354809e+00 -2.72412443e+00\n",
      "  -3.56992579e+00 -9.27983284e+00]\n",
      " [-1.43610859e+01 -8.34850597e+00 -1.09806547e+01 -3.45778561e+00\n",
      "  -5.50751925e-01 -5.36499929e+00 -1.87866116e+01 -3.77487898e+00\n",
      "  -8.78273964e-01  9.41287136e+00]\n",
      " [ 1.31750336e+01 -1.68432674e+01 -1.88046622e+00 -1.30268946e+01\n",
      "  -1.23034763e+01 -8.21224117e+00 -8.52369189e-01 -8.32797432e+00\n",
      "  -7.85209656e-01 -3.04535246e+00]\n",
      " [-1.00842600e+01 -1.15441875e+01 -1.10826807e+01 -5.66986895e+00\n",
      "  -1.25810802e+00 -9.55211639e+00 -1.61547508e+01  1.74971616e+00\n",
      "  -3.43753886e+00  8.31242752e+00]\n",
      " [-6.62076330e+00  9.58008862e+00 -5.01874161e+00 -1.02299404e+01\n",
      "  -1.40756881e+00 -5.48815680e+00 -4.78507996e+00 -2.67481112e+00\n",
      "  -3.19371319e+00 -7.46318436e+00]\n",
      " [-6.58835649e+00  3.55775189e+00 -1.98994648e+00 -8.50564194e+00\n",
      "  -3.79380083e+00 -1.18794212e+01 -8.59068108e+00 -1.54580534e-01\n",
      "  -2.88250756e+00 -5.36030912e+00]\n",
      " [-1.84116316e+00 -9.90887833e+00 -1.36685495e+01 -6.44945765e+00\n",
      "  -9.38531590e+00  9.76517391e+00 -6.95579863e+00 -7.62121201e+00\n",
      "  -5.91538334e+00 -5.97725964e+00]\n",
      " [-7.88220453e+00 -6.02201843e+00 -3.79827714e+00 -4.33026791e+00\n",
      "  -8.53289604e+00 -8.80552483e+00 -2.05668030e+01  9.92526817e+00\n",
      "  -7.37240267e+00 -3.52182579e+00]\n",
      " [-1.17479687e+01 -2.79297352e+00 -1.21365156e+01 -7.81813335e+00\n",
      "   8.53301048e+00 -4.93827343e+00 -1.22337723e+01 -3.98023653e+00\n",
      "  -7.15364647e+00  4.66784716e-01]\n",
      " [-1.68208885e+01 -3.67219806e+00  6.29452419e+00 -4.19970465e+00\n",
      "  -3.88566518e+00 -1.22059793e+01 -9.32132339e+00 -6.65988350e+00\n",
      "  -3.75807571e+00 -1.10455093e+01]\n",
      " [-6.81577492e+00 -7.67471600e+00 -6.91318035e+00 -4.49197578e+00\n",
      "  -3.78712893e+00 -9.78517437e+00 -2.03617420e+01  8.12004185e+00\n",
      "  -8.51117229e+00  1.87882352e+00]\n",
      " [-1.30136623e+01 -6.88345313e-01 -9.71897793e+00 -7.97456169e+00\n",
      "   3.37858582e+00 -7.24775505e+00 -1.44268064e+01 -1.96627903e+00\n",
      "  -4.56752872e+00  5.52280903e-01]\n",
      " [-5.83757257e+00 -6.35973120e+00 -3.49161625e+00 -3.18158698e+00\n",
      "  -7.81012344e+00 -1.03406029e+01 -1.95704346e+01  8.16123104e+00\n",
      "  -9.12891483e+00 -1.05336857e+00]\n",
      " [-6.67983150e+00 -9.06729031e+00  3.15198153e-01 -2.45293069e+00\n",
      "  -1.05150537e+01 -1.35761395e+01 -1.83459358e+01  8.88368893e+00\n",
      "  -6.16656685e+00 -3.04178548e+00]\n",
      " [-8.79914188e+00 -1.67018833e+01 -6.93637848e+00 -2.44142151e+00\n",
      "  -5.83908606e+00  4.31539106e+00 -8.76101112e+00 -6.86725140e+00\n",
      "  -5.49596214e+00 -6.38033772e+00]\n",
      " [-1.64609623e+01 -5.68046141e+00 -8.37448597e+00 -1.09709234e+01\n",
      "   1.33767500e+01 -6.94771051e+00 -1.09508095e+01  6.12619996e-01\n",
      "  -7.62560797e+00 -8.32077217e+00]\n",
      " [-4.20453167e+00 -2.82525253e+00  6.75106335e+00 -4.95070362e+00\n",
      "  -1.18461246e+01 -1.16204653e+01 -6.62525129e+00 -5.43728352e+00\n",
      "  -3.61416435e+00 -1.24541502e+01]\n",
      " [-3.12653041e+00 -7.27061319e+00 -5.46178150e+00 -1.03080397e+01\n",
      "  -3.04835510e+00 -3.05376172e+00  1.19408903e+01 -1.10245323e+01\n",
      "  -5.57579851e+00 -1.20556707e+01]\n",
      " [-7.19070387e+00 -7.79410124e-01  6.46685600e+00 -5.52517605e+00\n",
      "  -9.71684647e+00 -1.27724676e+01 -1.26526489e+01 -2.70623422e+00\n",
      "  -3.61432934e+00 -9.88197708e+00]\n",
      " [-7.76472759e+00 -1.38950653e+01 -8.24397755e+00 -6.23242331e+00\n",
      "  -9.65118694e+00  3.86593604e+00 -6.29494858e+00 -6.24241304e+00\n",
      "  -2.73666382e+00 -3.54913616e+00]\n",
      " [-6.37563276e+00 -1.21989164e+01 -1.28637810e+01 -3.95610380e+00\n",
      "  -6.55144262e+00  7.94804764e+00 -3.68905687e+00 -1.09495564e+01\n",
      "  -2.66283774e+00 -6.34852648e+00]\n",
      " [-1.19994812e+01  2.57099438e+00 -5.68507433e+00 -4.98455763e+00\n",
      "  -2.25907636e+00 -5.33347750e+00 -8.21315289e+00 -3.68955040e+00\n",
      "  -3.24305010e+00 -5.37585163e+00]\n",
      " [-1.95695996e+00 -1.48767929e+01 -9.61595249e+00 -1.16560888e+01\n",
      "  -7.73711872e+00  3.19374943e+00  9.35286903e+00 -1.57890530e+01\n",
      "  -2.03114700e+00 -4.25908184e+00]\n",
      " [-4.55057573e+00 -4.97734356e+00 -1.78689384e+00 -5.86955595e+00\n",
      "  -7.33437634e+00 -1.16392260e+01 -1.52430067e+01  6.87892485e+00\n",
      "  -9.49493790e+00 -2.08365989e+00]\n",
      " [-7.20390844e+00 -4.53309250e+00 -3.11172771e+00 -4.14984882e-01\n",
      "  -8.11378479e+00 -1.05040150e+01 -2.16782475e+01  1.19177666e+01\n",
      "  -1.15030565e+01 -4.25126934e+00]\n",
      " [-1.07743502e+01 -6.23393106e+00 -1.04556446e+01 -1.03215961e+01\n",
      "   1.17950115e+01 -8.17129612e+00 -6.60784769e+00 -5.43011904e+00\n",
      "  -5.20310020e+00 -6.66318655e+00]\n",
      " [-7.00820541e+00 -1.40103865e+01 -7.76086426e+00 -5.50515461e+00\n",
      "  -2.41620779e+00 -1.11346292e+01 -1.40925951e+01 -3.36157870e+00\n",
      "  -3.09920073e+00  8.21070099e+00]\n",
      " [-1.13359709e+01 -1.25211258e+01 -6.19169855e+00 -7.53503847e+00\n",
      "  -6.53967285e+00 -2.25723982e+00 -2.91054535e+00 -1.00151825e+01\n",
      "   5.52289677e+00 -4.60169792e+00]\n",
      " [-8.21580982e+00 -4.25608063e+00 -3.62534523e+00 -2.00890803e+00\n",
      "  -6.81879187e+00 -8.46821976e+00 -1.87196712e+01  9.08198357e+00\n",
      "  -9.36923027e+00 -4.23480034e+00]\n",
      " [-1.10278378e+01 -9.74654198e+00 -3.55881095e+00 -4.45231104e+00\n",
      "  -7.55549526e+00 -6.45338631e+00 -1.03237219e+01 -8.21136475e+00\n",
      "   8.47745800e+00 -2.08213186e+00]\n",
      " [-6.09227705e+00 -1.05904016e+01  6.39344883e+00  2.27001381e+00\n",
      "  -1.54804420e+01 -9.13193607e+00 -9.89660072e+00 -9.68460274e+00\n",
      "   1.70315206e+00 -7.97494602e+00]\n",
      " [-1.00402558e+00 -2.74232125e+00 -6.41916656e+00 -9.57471943e+00\n",
      "  -3.54565001e+00 -2.89196968e+00  5.62677956e+00 -1.04704113e+01\n",
      "  -2.86089373e+00 -8.72117233e+00]\n",
      " [-1.25183887e+01 -6.03462696e+00 -6.49834061e+00 -2.74502492e+00\n",
      "  -6.45456171e+00 -8.06070137e+00 -1.27140188e+01  6.67691588e-01\n",
      "  -7.15681696e+00 -3.47995234e+00]\n",
      " [-2.03720808e+00 -8.43595600e+00 -6.46172714e+00 -1.11230545e+01\n",
      "  -1.86139560e+00 -5.74340630e+00  1.13782578e+01 -9.09295845e+00\n",
      "  -6.17251921e+00 -7.83515835e+00]\n",
      " [-5.78003263e+00 -2.07751255e+01 -5.53528929e+00 -4.98052120e+00\n",
      "  -1.13449078e+01 -5.62136984e+00 -4.46077299e+00 -1.35537987e+01\n",
      "   1.13999519e+01 -2.09775400e+00]\n",
      " [-9.23246956e+00 -3.55697966e+00 -7.53007507e+00 -9.55285454e+00\n",
      "  -5.66352558e+00 -8.69632339e+00 -7.32368183e+00 -8.58387661e+00\n",
      "   8.61544514e+00 -4.29430628e+00]\n",
      " [-8.47201633e+00 -1.37523060e+01 -6.73655272e+00  9.69696236e+00\n",
      "  -1.24761171e+01 -1.53574419e+00 -1.36608877e+01 -1.00271072e+01\n",
      "  -5.25253296e+00 -4.65898848e+00]\n",
      " [-9.04056549e+00 -1.20853214e+01 -6.99983025e+00 -5.83590889e+00\n",
      "  -8.59854794e+00 -3.43945122e+00 -8.33349228e+00 -1.00773869e+01\n",
      "   8.10154533e+00 -2.49132895e+00]\n",
      " [-1.08800812e+01 -4.72086716e+00  1.05791893e+01 -7.31773520e+00\n",
      "  -2.03038454e+00 -1.28553591e+01 -8.22907925e+00 -4.94663477e+00\n",
      "  -8.22926426e+00 -1.26715403e+01]\n",
      " [-5.45790434e+00  8.45287228e+00 -2.53873301e+00 -1.00385571e+01\n",
      "  -1.86854410e+00 -7.02950144e+00 -5.35454512e+00 -2.09042025e+00\n",
      "  -6.47389984e+00 -8.12678337e+00]\n",
      " [-4.55292892e+00 -1.08303566e+01  7.64148617e+00 -3.81673121e+00\n",
      "  -7.73046494e+00 -1.09870157e+01 -1.04011889e+01 -5.73972464e+00\n",
      "  -1.71762288e+00 -8.14117336e+00]\n",
      " [-8.13309860e+00 -1.35802984e+01  6.41787958e+00 -5.66008282e+00\n",
      "  -3.96207237e+00 -9.10917473e+00 -9.69483662e+00 -1.93717659e+00\n",
      "  -5.75451136e+00 -7.05965424e+00]\n",
      " [ 3.51800418e+00 -1.97988243e+01 -8.14374924e+00 -5.75490665e+00\n",
      "  -1.45179348e+01 -1.61999357e+00 -4.34817791e+00 -1.01276264e+01\n",
      "  -3.82653952e+00 -1.14733827e+00]\n",
      " [-1.17224712e+01 -7.34996271e+00 -8.97546482e+00 -5.46960640e+00\n",
      "   6.12547493e+00 -6.08984089e+00 -1.10237465e+01 -4.83445072e+00\n",
      "  -6.26276159e+00 -1.65554869e+00]\n",
      " [-7.00597763e+00  8.50601196e+00 -2.96430206e+00 -8.85345840e+00\n",
      "  -2.29801011e+00 -7.83427668e+00 -7.58553696e+00 -7.75098920e-01\n",
      "  -6.71256304e+00 -6.64086246e+00]\n",
      " [-9.47027969e+00 -5.02968931e+00 -4.98559141e+00 -4.34092045e+00\n",
      "  -5.27947044e+00 -1.03579865e+01 -1.83830471e+01  8.76657963e+00\n",
      "  -8.24930382e+00 -1.94328618e+00]\n",
      " [ 8.70333958e+00 -1.42468376e+01 -4.12966681e+00 -9.87110329e+00\n",
      "  -7.84400082e+00 -5.42332697e+00 -2.11547780e+00 -9.10309029e+00\n",
      "  -4.84797764e+00 -3.05460525e+00]\n",
      " [ 7.61454105e+00 -1.31727037e+01 -9.07752514e-01 -8.95002937e+00\n",
      "  -9.04036713e+00 -1.10349035e+01 -2.77528739e+00 -8.22602367e+00\n",
      "  -6.08853292e+00 -2.90252233e+00]\n",
      " [ 8.61693287e+00 -1.27417822e+01 -2.35903785e-01 -8.72897530e+00\n",
      "  -1.08036833e+01 -8.67418766e+00 -1.51930511e+00 -1.01625118e+01\n",
      "  -5.48182249e+00 -6.54741192e+00]\n",
      " [-6.78329945e+00  7.28054905e+00 -4.02888584e+00 -7.37348461e+00\n",
      "  -3.99014282e+00 -8.13993359e+00 -1.11291904e+01  2.14301562e+00\n",
      "  -4.49496794e+00 -5.70622587e+00]\n",
      " [-8.06299782e+00 -1.09762001e+01 -1.03833132e+01 -5.34005594e+00\n",
      "   3.70800018e-01 -1.14317245e+01 -9.61270618e+00 -5.54766321e+00\n",
      "  -1.16533494e+00  6.01436567e+00]\n",
      " [ 1.11491938e+01 -1.60930500e+01 -4.06654215e+00 -1.31582890e+01\n",
      "  -9.22891521e+00 -3.80914044e+00  1.93252850e+00 -9.69314766e+00\n",
      "  -4.33448076e+00 -6.29199791e+00]\n",
      " [-7.88048553e+00  9.40073299e+00 -5.02353954e+00 -8.51653385e+00\n",
      "  -2.43489170e+00 -6.00225639e+00 -5.40378141e+00 -5.32842112e+00\n",
      "  -4.10900784e+00 -7.40073633e+00]\n",
      " [-4.24088287e+00 -1.54146748e+01 -8.04977226e+00 -1.05468445e+01\n",
      "  -5.62781334e+00 -1.28073621e+00  1.20353842e+01 -1.34546261e+01\n",
      "   2.62104839e-01 -6.91417933e+00]\n",
      " [-9.52567196e+00 -1.33684893e+01 -7.99036217e+00 -3.04322052e+00\n",
      "  -1.03461342e+01  5.88246250e+00 -5.52203703e+00 -1.59129801e+01\n",
      "   1.07802761e+00 -9.29325223e-01]\n",
      " [-7.95578337e+00 -1.60819683e+01 -3.94919014e+00 -2.83368206e+00\n",
      "  -1.33460569e+01 -2.58291078e+00 -9.13613605e+00 -1.44959688e+01\n",
      "   1.09096422e+01 -3.44038033e+00]\n",
      " [-7.98692465e+00 -1.47660875e+01 -3.54099321e+00 -5.53779697e+00\n",
      "  -9.11170864e+00 -7.31754112e+00 -2.38684773e+00 -1.44643803e+01\n",
      "   1.17607775e+01 -1.34617472e+00]\n",
      " [-1.42472401e+01 -5.63651562e+00  7.23144913e+00 -6.80816126e+00\n",
      "  -6.24155331e+00 -1.18478155e+01 -1.42670441e+01 -2.72005177e+00\n",
      "  -2.24550200e+00 -6.27828217e+00]\n",
      " [ 9.10538435e-02 -1.27145748e+01 -6.73331642e+00 -6.94469643e+00\n",
      "  -1.01346531e+01 -6.92812204e+00 -6.75471973e+00 -1.51398020e+01\n",
      "   7.11774635e+00  6.06996059e-01]\n",
      " [-9.55656815e+00 -1.52181129e+01 -6.83960867e+00 -1.16078901e+00\n",
      "  -9.89491653e+00 -8.03418756e-02 -1.44392319e+01 -1.07741566e+01\n",
      "  -2.45405746e+00  2.03644609e+00]\n",
      " [-1.04539175e+01 -1.36309195e+01 -1.21265926e+01 -4.71664238e+00\n",
      "  -1.66955781e+00 -2.32079744e+00 -1.67426567e+01 -2.55037689e+00\n",
      "  -2.61591148e+00  8.82313824e+00]\n",
      " [-1.28839531e+01 -3.48762989e+00  8.99483967e+00 -3.56689095e-03\n",
      "  -5.97920132e+00 -1.01289949e+01 -1.02183924e+01 -2.68422437e+00\n",
      "  -1.00634851e+01 -1.39877710e+01]\n",
      " [-1.08901148e+01 -1.38439760e+01 -2.11125541e+00  7.87876225e+00\n",
      "  -1.41077709e+01 -6.23393536e+00 -7.94378471e+00 -9.86163139e+00\n",
      "  -2.96966624e+00 -8.23420525e+00]\n",
      " [-9.59256458e+00 -1.48069258e+01 -1.38183641e+01 -2.55398607e+00\n",
      "  -9.45241261e+00  1.11805086e+01 -4.28128386e+00 -1.31700249e+01\n",
      "  -1.02033460e+00 -3.27010155e+00]\n",
      " [-8.33861542e+00 -8.09237099e+00 -7.32960033e+00 -7.79799843e+00\n",
      "   7.42220223e-01 -8.69981956e+00 -6.88241959e+00 -2.87084198e+00\n",
      "  -5.97758341e+00 -2.88319707e+00]\n",
      " [-5.08950329e+00  8.77558613e+00 -4.86699438e+00 -9.20717239e+00\n",
      "  -2.41434622e+00 -5.98364782e+00 -5.91143417e+00 -1.70636129e+00\n",
      "  -4.11238909e+00 -5.94527626e+00]\n",
      " [ 5.62193346e+00 -1.58588743e+01 -2.12619090e+00 -6.72090387e+00\n",
      "  -1.17172832e+01 -7.98541737e+00 -6.53504515e+00 -8.69302177e+00\n",
      "   2.37954211e+00 -1.50233305e+00]\n",
      " [-1.03680429e+01 -1.12390051e+01 -6.62474155e+00 -5.43218184e+00\n",
      "  -2.62654614e+00 -6.12675476e+00 -1.19016590e+01 -6.11675835e+00\n",
      "  -6.45810795e+00  6.60943794e+00]\n",
      " [-2.43351197e+00 -3.68985128e+00  8.46796131e+00 -4.77877188e+00\n",
      "  -9.21029472e+00 -1.61418419e+01 -4.57956553e+00 -7.69293308e+00\n",
      "  -4.94095373e+00 -1.07696285e+01]\n",
      " [-1.38435307e+01 -9.93219662e+00 -5.56227398e+00 -6.03564644e+00\n",
      "   8.47500515e+00 -9.89543247e+00 -8.46939468e+00 -5.05926466e+00\n",
      "  -9.05684376e+00 -1.89294970e+00]\n",
      " [-1.08957968e+01 -1.02509165e+01 -6.88394451e+00  8.58883095e+00\n",
      "  -1.36210403e+01 -2.09678364e+00 -1.31988888e+01 -2.60223293e+00\n",
      "  -5.02133560e+00 -1.00628338e+01]\n",
      " [-6.08189344e+00 -7.45699596e+00 -8.29591560e+00 -1.02307653e+01\n",
      "  -2.32232356e+00 -1.85039306e+00  9.09622192e+00 -8.25323105e+00\n",
      "  -6.31527710e+00 -1.03311415e+01]\n",
      " [-4.22807121e+00 -8.43063354e+00 -6.81199265e+00 -7.10085630e+00\n",
      "  -2.87191367e+00 -7.92699337e+00 -1.51953926e+01  7.81677008e+00\n",
      "  -1.00438499e+01 -4.86713290e-01]\n",
      " [-8.92374420e+00 -8.69713306e+00  8.12146664e+00 -5.94760895e-01\n",
      "  -1.45168333e+01 -1.38516645e+01 -8.13422966e+00 -9.22333336e+00\n",
      "  -1.09606862e-01 -7.29175663e+00]\n",
      " [ 9.26395798e+00 -1.31137400e+01 -5.56094503e+00 -8.32217884e+00\n",
      "  -1.45886927e+01 -3.92167354e+00 -1.63632464e+00 -1.33307371e+01\n",
      "  -4.17765188e+00 -2.13659465e-01]\n",
      " [-5.04167891e+00 -1.12778559e+01 -8.52975750e+00 -5.69965601e+00\n",
      "  -3.94825459e+00 -9.91967082e-01  1.10374584e+01 -1.54583759e+01\n",
      "  -8.02771807e-01 -8.64089870e+00]\n",
      " [-1.80195093e+00 -1.10720053e+01 -7.21101093e+00 -9.88560677e+00\n",
      "  -4.98685598e+00 -1.81684601e+00  1.16779585e+01 -1.46958761e+01\n",
      "  -1.00468457e-01 -1.03870020e+01]\n",
      " [-5.25495911e+00  3.69711494e+00 -6.58533049e+00 -9.69887352e+00\n",
      "  -2.31644154e+00 -8.80651951e+00 -6.40937138e+00 -3.92417252e-01\n",
      "  -3.65035820e+00 -4.81737185e+00]\n",
      " [-9.43900776e+00 -5.25685692e+00 -9.38416290e+00 -1.00221100e+01\n",
      "   4.94783878e+00 -5.70574951e+00 -9.41947556e+00 -5.89140797e+00\n",
      "  -5.53647566e+00 -2.10935545e+00]\n",
      " [-1.41961527e+01 -9.27872944e+00 -7.06957245e+00  1.21686716e+01\n",
      "  -1.20289192e+01 -3.26515436e+00 -1.64110622e+01 -5.96239853e+00\n",
      "  -4.46536779e+00 -3.63529778e+00]\n",
      " [-1.02111349e+01 -1.13060141e+01 -9.42782307e+00 -4.90849352e+00\n",
      "  -4.93494034e+00 -7.31330156e+00 -1.46655407e+01 -2.20003295e+00\n",
      "  -6.97434545e-01  4.64328241e+00]\n",
      " [-1.07325239e+01 -5.40590811e+00 -3.39318347e+00 -5.97104979e+00\n",
      "  -5.70900440e+00 -6.57900906e+00 -1.66695061e+01  8.39923954e+00\n",
      "  -8.87579441e+00 -3.39005566e+00]\n",
      " [-1.42594566e+01 -9.14692593e+00 -9.44422436e+00 -1.14159889e+01\n",
      "   6.47016096e+00 -4.43902493e+00 -8.11505699e+00 -1.48414564e+00\n",
      "  -3.48176074e+00 -4.48676062e+00]]\n"
     ]
    }
   ],
   "source": [
    "print (answers[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 9 0 3 7 0 3 0 3 5 7 4 0 4 3 3 1 9 0 9 1 1 5 7 4 2 7 4 7 7 5 4 2 6 2 5\n",
      " 5 1 6 7 7 4 9 8 7 8 2 6 7 6 8 8 3 8 2 1 2 2 0 4 1 7 0 0 0 1 9 0 1 6 5 8 8\n",
      " 2 8 9 9 2 3 5 4 1 0 9 2 4 3 6 7 2 0 6 6 1 4 3 9 7 4 0 9 2 0 7 3 0 5 0 8 0\n",
      " 0 4 7 1 7 1 1 3 3 3 7 2 8 6 3 8 7 8 4 3 5 6 0 0 0 3 1 3 6 4 3 4 5 5 8 7 7\n",
      " 2 8 4 3 5 6 5 3 7 5 7 8 3 0 4 5 1 2 7 6 3 0 2 7 8 6 1 3 7 4 1 2 4 8 5 2 4\n",
      " 9 2 1 6 0 6 1 4 9 6 0 9 7 6 9 1 9 0 9 9 0 8 4 6 2 0 9 3 6 3 2 1 6 3 4 2 3\n",
      " 1 2 2 0 4 6 1 0 0 4 9 1 7 3 2 3 8 6 8 6 2 8 5 5 4 8 3 5 9 7 1 3 8 4 5 1 4\n",
      " 5 6 3 3 5 7 0 6 8 3 1 6 0 6 3 9 5 1 5 8 4 0 9 2 0 5 3 7 1 9 9 5 7 7 9 9 6\n",
      " 3 0 3 3 6 9 8 2 6 3 7 1 4 5 8 5 9 0 0 3 8 4 1 8 4 1 1 9 8 4 5 1 5 3 6 3 1\n",
      " 3 0 9 0 0 6 0 6 3 1 8 6 0 6 5 2 2 6 7 7 2 5 8 3 9 2 7 8 6 3 8 4 2 3 8 1 6\n",
      " 4 8 7 9 7 6 9 5 3 7 6 5 5 4 2 6 2 1 3 7 1 7 9 9 6 1 1 1 7 3 9 7 6 1 1 1 9\n",
      " 3 8 5 5 0 4 1 2 3 1 1 3 5 9 6 6 5 3 1 4 7 4 7 4 8 5 2 6 1 3 9 5 0 8 4 7 4\n",
      " 4 4 1 5 3 9 9 7 6 9 5 9 2 3 5 6 6 7 5 0 5 1 7 4 4 1 1 4 9 5 6 0 1 3 1 0 4\n",
      " 8 1 2 7 9 4 8 3 7 7 4 2 4 6 7 6 3 2 0 6 5 9 4 1 8 3 3 0 2 7 5 8 7 5 3 5 7\n",
      " 4 3 6 9 0 7 7 1 0 1 1 7 0 5 3 8 3 5 6 5 7 3 0 2 8 2 0 3 0 9 2 1 1 3 0 5 5\n",
      " 0 7 5 6 2 0 3 8 1 6 5 4 1 1 4 6 5 3 6 0 4 8 2 4 2 5 1 7 6 9 1 7 3 8 0 8 8\n",
      " 4 5 3 6 6 6 0 3 5 1 7 1 6 2 8 5 6 4 7 4 3 3 2 4 7 0 0 9 8 5 9 4 0 8 8 3 6\n",
      " 2 6 1 8 6 1 4 7 7 8 3 0 9 9 6 7 7 4 4 1 8 4 8 0 2 8 2 4 3 3 7 2 3 4 0 4 8\n",
      " 1 3 3 6 3 9 4 3 8 7 7 2 6 0 6 9 8 8 1 3 4 6 9 9 2 6 0 1 8 4 3 9 8 8 4 0 5\n",
      " 0 6 0 4 4 6 5 1 8 1 5 3 6 2 3 7 8 9 3 1 0 1 0 6 4 7 5 7 1 3 2 7 7 1 5 1 5\n",
      " 4 4 3 4 3 9 0 7 8 6 4 9 4 4 1 4 7 1 1 8 7 0 4 0 4 0 0 5 1 8 6 5 0 1 5 3 4\n",
      " 6 3 1 1 6 9 8 3 5 5 4 8 6 5 0 4 0 4 3 1 6 9 9 1 1 3 3 1 4 9 6 9 1 5 4 2 3\n",
      " 2 4 0 9 7 4 3 0 5 0 1 9 0 4 5 2 8 8 5 9 3 9 6 1 5 5 1 9 0 8 7 6 7 2 8 5 8\n",
      " 9 7 7 2 8 1 3 4 5 0 4 1 4 2 3 6 9 2 3 4 5 4 2 3 3 1 1 0 1 4 9 1 1 2 7 1 5\n",
      " 4 9 1 7 6 0 4 2 9 4 1 1 5 3 5 7 9 7 8 3 2 7 2 0 4 7 1 6 4 6 1 5 7 3 5 9 4\n",
      " 7 9 6 6 3 3 2 1 4 5 3 7 7 9 5 6 3 6 1 0 9 3 2 9 2 6 7 5 2 3 2 8 3 0 2 7 9\n",
      " 4 0 9 5 1 8 8 5 3 2 9 6 7 0 8 0 7 4 5 8 7 9 7 7 0 5 3 2 1 9 0 6 8 3 6 2 2\n",
      " 9]\n"
     ]
    }
   ],
   "source": [
    "print (vals[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"submission.txt\", \"w\") as fout:\n",
    "    fout.write(\"ImageId,Label\\n\")\n",
    "    for i, val in enumerate(vals):\n",
    "        fout.write(\"{},{}\\n\".format(str(i+1), str(val)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
